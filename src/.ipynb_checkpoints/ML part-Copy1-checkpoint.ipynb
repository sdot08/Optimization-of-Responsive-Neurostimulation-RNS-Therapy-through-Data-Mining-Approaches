{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import operator\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "#PLOT CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import pickle\n",
    "#matrix inverse\n",
    "from numpy.linalg import inv\n",
    "import jj_basic_fn as JJ\n",
    "from hyperparams import Hyperparams as hp\n",
    "from patient import patient\n",
    "import prep\n",
    "import plot_funcs\n",
    "import modules\n",
    "#default size of the graph\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "n_classifier = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>region_start_time</th>\n",
       "      <th>long_epi</th>\n",
       "      <th>sleep</th>\n",
       "      <th>delta1</th>\n",
       "      <th>delta2</th>\n",
       "      <th>delta3</th>\n",
       "      <th>delta4</th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "      <th>...</th>\n",
       "      <th>all1</th>\n",
       "      <th>all2</th>\n",
       "      <th>all3</th>\n",
       "      <th>all4</th>\n",
       "      <th>i12</th>\n",
       "      <th>i34</th>\n",
       "      <th>epoch</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>if_stimulated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 05:42:50.000025600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>680.164478</td>\n",
       "      <td>566.940835</td>\n",
       "      <td>170.649179</td>\n",
       "      <td>662.119967</td>\n",
       "      <td>443.540208</td>\n",
       "      <td>728.059167</td>\n",
       "      <td>...</td>\n",
       "      <td>1550.816935</td>\n",
       "      <td>4366.540841</td>\n",
       "      <td>704.101182</td>\n",
       "      <td>1870.300441</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 05:44:46.999968000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>833.779602</td>\n",
       "      <td>651.250164</td>\n",
       "      <td>164.036945</td>\n",
       "      <td>828.162406</td>\n",
       "      <td>568.359164</td>\n",
       "      <td>825.928353</td>\n",
       "      <td>...</td>\n",
       "      <td>2091.945339</td>\n",
       "      <td>3784.473808</td>\n",
       "      <td>650.644315</td>\n",
       "      <td>1967.422976</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 06:24:08.999971200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>203.235705</td>\n",
       "      <td>264.172585</td>\n",
       "      <td>105.114985</td>\n",
       "      <td>210.849406</td>\n",
       "      <td>285.520004</td>\n",
       "      <td>333.247015</td>\n",
       "      <td>...</td>\n",
       "      <td>956.335500</td>\n",
       "      <td>2125.860434</td>\n",
       "      <td>356.339025</td>\n",
       "      <td>975.387852</td>\n",
       "      <td>68.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 10:57:08.000035200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.641848</td>\n",
       "      <td>110.515245</td>\n",
       "      <td>70.882142</td>\n",
       "      <td>113.874863</td>\n",
       "      <td>246.154818</td>\n",
       "      <td>183.792996</td>\n",
       "      <td>...</td>\n",
       "      <td>730.524124</td>\n",
       "      <td>570.193897</td>\n",
       "      <td>309.129564</td>\n",
       "      <td>701.366684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1.315211e+17</td>\n",
       "      <td>2017-10-10 05:02:14.999971200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>986.767934</td>\n",
       "      <td>332.538069</td>\n",
       "      <td>143.791948</td>\n",
       "      <td>290.389210</td>\n",
       "      <td>624.991166</td>\n",
       "      <td>498.583798</td>\n",
       "      <td>...</td>\n",
       "      <td>1945.942254</td>\n",
       "      <td>2626.879371</td>\n",
       "      <td>481.380802</td>\n",
       "      <td>1000.853758</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1.315211e+17</td>\n",
       "      <td>2017-10-10 05:49:13.999987200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.760449</td>\n",
       "      <td>171.131138</td>\n",
       "      <td>65.142623</td>\n",
       "      <td>320.504534</td>\n",
       "      <td>138.982599</td>\n",
       "      <td>563.006368</td>\n",
       "      <td>...</td>\n",
       "      <td>563.606901</td>\n",
       "      <td>1463.561433</td>\n",
       "      <td>311.665486</td>\n",
       "      <td>1066.018519</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1.315211e+17</td>\n",
       "      <td>2017-10-10 05:59:22.999977600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.699012</td>\n",
       "      <td>208.390401</td>\n",
       "      <td>39.528188</td>\n",
       "      <td>119.645249</td>\n",
       "      <td>196.736448</td>\n",
       "      <td>633.993093</td>\n",
       "      <td>...</td>\n",
       "      <td>611.528257</td>\n",
       "      <td>1775.664988</td>\n",
       "      <td>195.864273</td>\n",
       "      <td>771.352481</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>1.315224e+17</td>\n",
       "      <td>2017-10-11 05:41:48.999984000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>892.982169</td>\n",
       "      <td>213.389915</td>\n",
       "      <td>89.680107</td>\n",
       "      <td>311.030932</td>\n",
       "      <td>649.320535</td>\n",
       "      <td>377.638450</td>\n",
       "      <td>...</td>\n",
       "      <td>2032.449958</td>\n",
       "      <td>1821.729925</td>\n",
       "      <td>406.767717</td>\n",
       "      <td>1097.778721</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1.315224e+17</td>\n",
       "      <td>2017-10-11 09:47:15.000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993069</td>\n",
       "      <td>106.881199</td>\n",
       "      <td>26.926312</td>\n",
       "      <td>55.914169</td>\n",
       "      <td>149.341963</td>\n",
       "      <td>111.237546</td>\n",
       "      <td>...</td>\n",
       "      <td>488.439388</td>\n",
       "      <td>365.052833</td>\n",
       "      <td>173.857826</td>\n",
       "      <td>346.042817</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>1.315224e+17</td>\n",
       "      <td>2017-10-11 10:56:36.999974400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.761414</td>\n",
       "      <td>84.211143</td>\n",
       "      <td>49.556652</td>\n",
       "      <td>64.207501</td>\n",
       "      <td>196.764906</td>\n",
       "      <td>219.796690</td>\n",
       "      <td>...</td>\n",
       "      <td>449.679310</td>\n",
       "      <td>516.559761</td>\n",
       "      <td>237.941349</td>\n",
       "      <td>523.882146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>1.317872e+17</td>\n",
       "      <td>2018-08-14 03:54:57.999974400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.685450</td>\n",
       "      <td>186.150067</td>\n",
       "      <td>247.556372</td>\n",
       "      <td>530.193752</td>\n",
       "      <td>281.346825</td>\n",
       "      <td>456.867931</td>\n",
       "      <td>...</td>\n",
       "      <td>858.464745</td>\n",
       "      <td>1378.834652</td>\n",
       "      <td>576.554965</td>\n",
       "      <td>1296.243336</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>1.317872e+17</td>\n",
       "      <td>2018-08-14 03:57:31.000032000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.720402</td>\n",
       "      <td>154.098863</td>\n",
       "      <td>66.905656</td>\n",
       "      <td>168.993628</td>\n",
       "      <td>125.509104</td>\n",
       "      <td>199.235483</td>\n",
       "      <td>...</td>\n",
       "      <td>545.891380</td>\n",
       "      <td>776.247331</td>\n",
       "      <td>254.236557</td>\n",
       "      <td>769.437289</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:32:06.999993600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.302667</td>\n",
       "      <td>204.060698</td>\n",
       "      <td>61.567870</td>\n",
       "      <td>129.473618</td>\n",
       "      <td>151.700226</td>\n",
       "      <td>238.357193</td>\n",
       "      <td>...</td>\n",
       "      <td>435.504264</td>\n",
       "      <td>705.129978</td>\n",
       "      <td>391.489705</td>\n",
       "      <td>851.911912</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:34:48.000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.442444</td>\n",
       "      <td>194.976844</td>\n",
       "      <td>69.401723</td>\n",
       "      <td>176.100460</td>\n",
       "      <td>336.441055</td>\n",
       "      <td>428.506186</td>\n",
       "      <td>...</td>\n",
       "      <td>711.953822</td>\n",
       "      <td>1152.180676</td>\n",
       "      <td>557.760074</td>\n",
       "      <td>1606.703946</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:36:20.000016000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.507380</td>\n",
       "      <td>120.821675</td>\n",
       "      <td>76.659557</td>\n",
       "      <td>140.764908</td>\n",
       "      <td>267.030774</td>\n",
       "      <td>305.850460</td>\n",
       "      <td>...</td>\n",
       "      <td>856.653862</td>\n",
       "      <td>802.170815</td>\n",
       "      <td>447.913528</td>\n",
       "      <td>1408.176729</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:41:36.999974400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.315376</td>\n",
       "      <td>205.774419</td>\n",
       "      <td>209.640074</td>\n",
       "      <td>184.750419</td>\n",
       "      <td>265.558684</td>\n",
       "      <td>196.383871</td>\n",
       "      <td>...</td>\n",
       "      <td>985.883354</td>\n",
       "      <td>782.704552</td>\n",
       "      <td>633.300497</td>\n",
       "      <td>939.395912</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:44:42.000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.279724</td>\n",
       "      <td>125.160093</td>\n",
       "      <td>74.616125</td>\n",
       "      <td>86.633713</td>\n",
       "      <td>203.093098</td>\n",
       "      <td>185.279175</td>\n",
       "      <td>...</td>\n",
       "      <td>582.371854</td>\n",
       "      <td>658.805627</td>\n",
       "      <td>553.213019</td>\n",
       "      <td>1128.052698</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:56:29.999961600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.858818</td>\n",
       "      <td>75.122268</td>\n",
       "      <td>30.789880</td>\n",
       "      <td>66.254857</td>\n",
       "      <td>393.952639</td>\n",
       "      <td>288.818356</td>\n",
       "      <td>...</td>\n",
       "      <td>790.190645</td>\n",
       "      <td>786.013605</td>\n",
       "      <td>205.459872</td>\n",
       "      <td>572.788956</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 18:16:36.000019200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.027158</td>\n",
       "      <td>80.026866</td>\n",
       "      <td>100.414808</td>\n",
       "      <td>167.994568</td>\n",
       "      <td>354.762262</td>\n",
       "      <td>295.805692</td>\n",
       "      <td>...</td>\n",
       "      <td>787.298299</td>\n",
       "      <td>720.698506</td>\n",
       "      <td>286.724859</td>\n",
       "      <td>677.111457</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 18:32:13.999977600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>475.421437</td>\n",
       "      <td>416.388456</td>\n",
       "      <td>315.003093</td>\n",
       "      <td>476.676144</td>\n",
       "      <td>324.026765</td>\n",
       "      <td>398.041372</td>\n",
       "      <td>...</td>\n",
       "      <td>1020.379692</td>\n",
       "      <td>1266.256582</td>\n",
       "      <td>1016.276424</td>\n",
       "      <td>1542.254848</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename             region_start_time  long_epi  sleep      delta1  \\\n",
       "1633  1.315205e+17 2017-10-09 05:42:50.000025600  1.0       1.0    680.164478   \n",
       "1634  1.315205e+17 2017-10-09 05:44:46.999968000  1.0       1.0    833.779602   \n",
       "1635  1.315205e+17 2017-10-09 06:24:08.999971200  1.0       1.0    203.235705   \n",
       "1636  1.315205e+17 2017-10-09 10:57:08.000035200  0.0       0.0    112.641848   \n",
       "1637  1.315211e+17 2017-10-10 05:02:14.999971200  1.0       1.0    986.767934   \n",
       "1638  1.315211e+17 2017-10-10 05:49:13.999987200  1.0       1.0    136.760449   \n",
       "1639  1.315211e+17 2017-10-10 05:59:22.999977600  1.0       1.0    134.699012   \n",
       "1640  1.315224e+17 2017-10-11 05:41:48.999984000  1.0       1.0    892.982169   \n",
       "1641  1.315224e+17 2017-10-11 09:47:15.000000000  1.0       0.0    99.993069    \n",
       "1642  1.315224e+17 2017-10-11 10:56:36.999974400  0.0       0.0    77.761414    \n",
       "...            ...                           ...  ...       ...          ...    \n",
       "2738  1.317872e+17 2018-08-14 03:54:57.999974400  1.0       1.0    264.685450   \n",
       "2739  1.317872e+17 2018-08-14 03:57:31.000032000  1.0       1.0    146.720402   \n",
       "2740  1.317877e+17 2018-08-14 17:32:06.999993600  1.0       0.0    92.302667    \n",
       "2741  1.317877e+17 2018-08-14 17:34:48.000000000  1.0       0.0    136.442444   \n",
       "2742  1.317877e+17 2018-08-14 17:36:20.000016000  1.0       0.0    232.507380   \n",
       "2743  1.317877e+17 2018-08-14 17:41:36.999974400  1.0       0.0    423.315376   \n",
       "2744  1.317877e+17 2018-08-14 17:44:42.000000000  1.0       0.0    87.279724    \n",
       "2745  1.317877e+17 2018-08-14 17:56:29.999961600  1.0       0.0    151.858818   \n",
       "2746  1.317877e+17 2018-08-14 18:16:36.000019200  1.0       0.0    173.027158   \n",
       "2747  1.317877e+17 2018-08-14 18:32:13.999977600  1.0       0.0    475.421437   \n",
       "\n",
       "          delta2      delta3      delta4      theta1      theta2  \\\n",
       "1633  566.940835  170.649179  662.119967  443.540208  728.059167   \n",
       "1634  651.250164  164.036945  828.162406  568.359164  825.928353   \n",
       "1635  264.172585  105.114985  210.849406  285.520004  333.247015   \n",
       "1636  110.515245  70.882142   113.874863  246.154818  183.792996   \n",
       "1637  332.538069  143.791948  290.389210  624.991166  498.583798   \n",
       "1638  171.131138  65.142623   320.504534  138.982599  563.006368   \n",
       "1639  208.390401  39.528188   119.645249  196.736448  633.993093   \n",
       "1640  213.389915  89.680107   311.030932  649.320535  377.638450   \n",
       "1641  106.881199  26.926312   55.914169   149.341963  111.237546   \n",
       "1642  84.211143   49.556652   64.207501   196.764906  219.796690   \n",
       "...         ...         ...         ...          ...         ...   \n",
       "2738  186.150067  247.556372  530.193752  281.346825  456.867931   \n",
       "2739  154.098863  66.905656   168.993628  125.509104  199.235483   \n",
       "2740  204.060698  61.567870   129.473618  151.700226  238.357193   \n",
       "2741  194.976844  69.401723   176.100460  336.441055  428.506186   \n",
       "2742  120.821675  76.659557   140.764908  267.030774  305.850460   \n",
       "2743  205.774419  209.640074  184.750419  265.558684  196.383871   \n",
       "2744  125.160093  74.616125   86.633713   203.093098  185.279175   \n",
       "2745  75.122268   30.789880   66.254857   393.952639  288.818356   \n",
       "2746  80.026866   100.414808  167.994568  354.762262  295.805692   \n",
       "2747  416.388456  315.003093  476.676144  324.026765  398.041372   \n",
       "\n",
       "          ...               all1         all2         all3         all4   i12  \\\n",
       "1633      ...        1550.816935  4366.540841  704.101182   1870.300441  28.0   \n",
       "1634      ...        2091.945339  3784.473808  650.644315   1967.422976  34.0   \n",
       "1635      ...        956.335500   2125.860434  356.339025   975.387852   68.0   \n",
       "1636      ...        730.524124   570.193897   309.129564   701.366684   0.0    \n",
       "1637      ...        1945.942254  2626.879371  481.380802   1000.853758  26.0   \n",
       "1638      ...        563.606901   1463.561433  311.665486   1066.018519  61.0   \n",
       "1639      ...        611.528257   1775.664988  195.864273   771.352481   63.0   \n",
       "1640      ...        2032.449958  1821.729925  406.767717   1097.778721  28.0   \n",
       "1641      ...        488.439388   365.052833   173.857826   346.042817   20.0   \n",
       "1642      ...        449.679310   516.559761   237.941349   523.882146   0.0    \n",
       "...       ...               ...          ...          ...          ...   ...    \n",
       "2738      ...        858.464745   1378.834652  576.554965   1296.243336  33.0   \n",
       "2739      ...        545.891380   776.247331   254.236557   769.437289   25.0   \n",
       "2740      ...        435.504264   705.129978   391.489705   851.911912   20.0   \n",
       "2741      ...        711.953822   1152.180676  557.760074   1606.703946  41.0   \n",
       "2742      ...        856.653862   802.170815   447.913528   1408.176729  30.0   \n",
       "2743      ...        985.883354   782.704552   633.300497   939.395912   40.0   \n",
       "2744      ...        582.371854   658.805627   553.213019   1128.052698  13.0   \n",
       "2745      ...        790.190645   786.013605   205.459872   572.788956   31.0   \n",
       "2746      ...        787.298299   720.698506   286.724859   677.111457   29.0   \n",
       "2747      ...        1020.379692  1266.256582  1016.276424  1542.254848  40.0   \n",
       "\n",
       "       i34  epoch  label   id  if_stimulated  \n",
       "1633  16.0  0      True   229  False          \n",
       "1634  14.0  0      True   229  False          \n",
       "1635  27.0  0      True   229  False          \n",
       "1636  0.0   0      True   229  False          \n",
       "1637  20.0  0      True   229  False          \n",
       "1638  18.0  0      True   229  False          \n",
       "1639  19.0  0      True   229  False          \n",
       "1640  16.0  0      True   229  False          \n",
       "1641  15.0  0      True   229  False          \n",
       "1642  0.0   0      True   229  False          \n",
       "...   ...  ..       ...   ...    ...          \n",
       "2738  17.0  9      False  229  False          \n",
       "2739  11.0  9      False  229  False          \n",
       "2740  9.0   9      False  229  False          \n",
       "2741  25.0  9      False  229  False          \n",
       "2742  20.0  9      False  229  False          \n",
       "2743  25.0  9      False  229  False          \n",
       "2744  7.0   9      False  229  False          \n",
       "2745  20.0  9      False  229  False          \n",
       "2746  15.0  9      False  229  False          \n",
       "2747  22.0  9      False  229  False          \n",
       "\n",
       "[1115 rows x 38 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p229.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hp/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/hp/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "#p231, p222_1, p222_2, p229 = modules.build_patients()\n",
    "p231, p222_1, p222_2, p229 = modules.build_patients()\n",
    "pat_list = [p231, p222_1, p222_2, p229]\n",
    "for pat in pat_list:\n",
    "    JJ.save_object(pat, '../patients/' + pat.id +'.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_rs = hp.col_rs\n",
    "col_es = hp.col_es\n",
    "col_le = hp.col_le\n",
    "\n",
    "p231, p222_1, p222_2, p222_3, p229 = \\\n",
    "pickle.load(open(hp.prepath_pat + \"231.p\", \"rb\" )),\\\n",
    "pickle.load(open(hp.prepath_pat + \"222_1.p\", \"rb\" )), \\\n",
    "pickle.load(open(hp.prepath_pat + \"222_2.p\", \"rb\" )), \\\n",
    "pickle.load(open(hp.prepath_pat + \"222_3.p\", \"rb\" )),\\\n",
    "pickle.load(open(hp.prepath_pat + \"229.p\", \"rb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_tuning(pat, X_train, X_test, y_train, y_test, classifier, C_range_num = 30, if_save = 0,\n",
    "                     nfold = 10, if_show = 1):\n",
    "    #defs is a dictionary to initiate classifier with the parameters that don't need to be tuned\n",
    "    defs = {}\n",
    "    defs['classifier'] = classifier\n",
    "    \n",
    "    num_instances, num_features = X_train.shape[0], X_train.shape[1]\n",
    "    n_fold = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    CV = skf.split(np.zeros(len(y_train)), y_train)\n",
    "    \n",
    "\n",
    "    if classifier==1:\n",
    "        clf_name = 'Logistic Regression'\n",
    "        defs['class_weight'] = 'balanced'\n",
    "        defs['max_iter'] = 200\n",
    "        C_range = 10 ** np.random.uniform(-2, 1, size = C_range_num)\n",
    "        tuned_params = dict(penalty=['l1','l2'], C=C_range)\n",
    "    elif classifier == 2: \n",
    "        clf_name = 'SVM'\n",
    "        defs['class_weight'] = 'balanced'\n",
    "        kernel_list = ['rbf']    \n",
    "        gamma_list = [2**i*1/num_features for i in range(1)]\n",
    "        #degree_list = [2,3,4,5]\n",
    "        C_range = 10 ** np.random.uniform(-3, 1, size = C_range_num)\n",
    "        tuned_params = dict(kernel=kernel_list,gamma = gamma_list, C=C_range)\n",
    "\n",
    "    elif classifier==3:\n",
    "        clf_name = 'Gaussian Naive Bayes classifier'\n",
    "        prr = np.ones(2) * (1.0/2)\n",
    "        defs['priors'] = prr\n",
    "        clf_try = JJ.clf_list(defs)\n",
    "        clf_try.fit(X_train, y_train)\n",
    "        pat.estimator[classifier] = clf_try\n",
    "        return\n",
    "\n",
    "    elif classifier==4:\n",
    "        clf_name = 'Linear Discriminant Analysis'\n",
    "        prr = np.ones(2) * (1.0/2)\n",
    "        defs['solver'] = 'eigen'  # 'svd', 'lsqr', 'eigen'\n",
    "        defs['shrinkage'] = 'auto'\n",
    "        defs['priors'] = prr\n",
    "        clf_try = JJ.clf_list(defs)\n",
    "        clf_try.fit(X_train, y_train)\n",
    "        pat.estimator[classifier] = clf_try\n",
    "        return\n",
    "    elif classifier == 5:\n",
    "        clf_name = 'decision tree'\n",
    "        mss_list = [5,10,20,40,60]\n",
    "        criterion_list = ['entropy']\n",
    "        max_depth_list = [3,4,5,8,12,18]\n",
    "        clf_name = 'decision tree'\n",
    "        tuned_params = dict(criterion=criterion_list, min_samples_split=mss_list, max_depth = max_depth_list)\n",
    "    elif classifier == 6:\n",
    "        clf_name = 'random forest'\n",
    "        defs['n_estimators'] = 600\n",
    "        mss_list = [20,25,30,40]\n",
    "        criterion_list = ['entropy']\n",
    "        max_depth_list = [12,13,14,15,16]\n",
    "        max_features_list = ['auto']\n",
    "        tuned_params = dict(criterion=criterion_list, min_samples_split=mss_list, max_depth = max_depth_list, max_features = max_features_list)\n",
    "    elif classifier == 7:\n",
    "        clf_name = 'gradient boosting'\n",
    "        defs['n_estimators'] = 2000\n",
    "        max_depth_list, subsample_list, learning_rate_list, min_samples_leaf_list = [1,2,3], [0.1,0.15,0.2, 0.3, 0.4], [0.02, 0.01,0.005], [10,20,30] \n",
    "        #params = {'n_estimators': 1200, 'max_depth': 3, 'subsample': 0.5,\n",
    "        #  'learning_rate': 0.01, 'min_samples_leaf': 10, 'random_state': 3}\n",
    "        tuned_params = dict(max_depth=max_depth_list, subsample = subsample_list,learning_rate = learning_rate_list, min_samples_leaf= min_samples_leaf_list)\n",
    "    \n",
    "        \n",
    "    clf_try = JJ.clf_list(defs)\n",
    "    \n",
    "    clf_grid = GridSearchCV(clf_try,\n",
    "                            param_grid=tuned_params,\n",
    "                            cv=CV,\n",
    "                            scoring = 'roc_auc',\n",
    "                            verbose=1,\n",
    "                           return_train_score = True)\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    print('Best score for validations set: {}'.format(clf_grid.best_score_))\n",
    "    print('Best parameters: {}'.format(clf_grid.best_params_))\n",
    "\n",
    "    clf_best = clf_grid.best_estimator_\n",
    "\n",
    "    y_pred = clf_best.predict(X_test)\n",
    "    df = pd.DataFrame(clf_grid.cv_results_)\n",
    "    if if_show:\n",
    "        JJ.show_result(y_pred, y_test, df, clf_name, if_save = if_save)\n",
    "    \n",
    "    if if_save:\n",
    "        pat.result[classifier] = df\n",
    "        pat.estimator[classifier] = clf_best\n",
    "        pat.score[classifier] = clf_grid.best_score_\n",
    "        pat.params[classifier] = clf_grid.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n",
      "Best score for validations set: 0.728700918964077\n",
      "Best parameters: {'penalty': 'l2', 'C': 0.06196918137944155}\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.06196918137944155}</td>\n",
       "      <td>0.728701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.06428409085929962}</td>\n",
       "      <td>0.728693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.08376818643305572}</td>\n",
       "      <td>0.728676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.08250564721819544}</td>\n",
       "      <td>0.728676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.08121988357466467}</td>\n",
       "      <td>0.728415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.07712476885084417}</td>\n",
       "      <td>0.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.08969076064936082}</td>\n",
       "      <td>0.728158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.06853552435886708}</td>\n",
       "      <td>0.728129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.06918594285670775}</td>\n",
       "      <td>0.727872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>{'penalty': 'l2', 'C': 0.0563957331324413}</td>\n",
       "      <td>0.727623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.014075317833727768}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.012656756687970125}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.012051840672665412}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.012042623704738412}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.01025450603233791}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.011993037672876536}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.014028174272223982}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.01852972943221925}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.015571883555248446}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>{'penalty': 'l1', 'C': 0.013024419166318283}</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score\n",
       "97   {'penalty': 'l2', 'C': 0.06196918137944155}   0.728701       \n",
       "197  {'penalty': 'l2', 'C': 0.06428409085929962}   0.728693       \n",
       "145  {'penalty': 'l2', 'C': 0.08376818643305572}   0.728676       \n",
       "15   {'penalty': 'l2', 'C': 0.08250564721819544}   0.728676       \n",
       "63   {'penalty': 'l2', 'C': 0.08121988357466467}   0.728415       \n",
       "83   {'penalty': 'l2', 'C': 0.07712476885084417}   0.728400       \n",
       "105  {'penalty': 'l2', 'C': 0.08969076064936082}   0.728158       \n",
       "5    {'penalty': 'l2', 'C': 0.06853552435886708}   0.728129       \n",
       "43   {'penalty': 'l2', 'C': 0.06918594285670775}   0.727872       \n",
       "95   {'penalty': 'l2', 'C': 0.0563957331324413}    0.727623       \n",
       "..                                          ...         ...       \n",
       "198  {'penalty': 'l1', 'C': 0.014075317833727768}  0.500000       \n",
       "64   {'penalty': 'l1', 'C': 0.012656756687970125}  0.500000       \n",
       "10   {'penalty': 'l1', 'C': 0.012051840672665412}  0.500000       \n",
       "178  {'penalty': 'l1', 'C': 0.012042623704738412}  0.500000       \n",
       "98   {'penalty': 'l1', 'C': 0.01025450603233791}   0.500000       \n",
       "180  {'penalty': 'l1', 'C': 0.011993037672876536}  0.500000       \n",
       "12   {'penalty': 'l1', 'C': 0.014028174272223982}  0.500000       \n",
       "140  {'penalty': 'l1', 'C': 0.01852972943221925}   0.500000       \n",
       "90   {'penalty': 'l1', 'C': 0.015571883555248446}  0.500000       \n",
       "132  {'penalty': 'l1', 'C': 0.013024419166318283}  0.500000       \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoIAAAJCCAYAAABUGKahAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRhAAAMBH0QgCAAD4qP8Hw/Lh45Q7AAkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17be8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = modules.get_ml_data(p2, if_remove_icd = 1, if_remove_sleep=1, if_remove_le=0, le_class = 1)\n",
    "parameter_tuning(p229,X_train, X_test, y_train, y_test,1, C_range_num = 100, \n",
    "                     nfold = 10, if_save = 0, if_show = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_tuning_all(pat, C_range_num, if_scaler = 1, if_remove_icd = 1, if_remove_sleep=1, if_remove_le = 1, le_class = None, if_save = 1, if_show = 0):\n",
    "    X_train, X_test, y_train, y_test = modules.get_ml_data(pat, if_scaler = if_scaler, if_remove_icd = if_remove_icd, if_remove_sleep = if_remove_sleep, if_remove_le = if_remove_le, le_class = le_class)\n",
    "    for classifier_int in tqdm.trange(1,hp.num_classifier + 1):\n",
    "        parameter_tuning(pat, X_train, X_test, y_train, y_test, C_range_num = C_range_num, classifier = classifier_int, if_save = if_save, if_show = if_show)\n",
    "    if if_save:\n",
    "        JJ.save_object(pat, hp.prepath_pat + pat.id +'_trained.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers removed: 0\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:    4.7s finished\n",
      "\n",
      " 14%|█▍        | 1/7 [00:04<00:28,  4.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.8288288288288288\n",
      "Best parameters: {'penalty': 'l1', 'C': 0.8619964922273167}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.3s finished\n",
      "\n",
      " 29%|██▊       | 2/7 [00:07<00:17,  3.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.8918918918918919\n",
      "Best parameters: {'gamma': 0.041666666666666664, 'kernel': 'rbf', 'C': 0.12881283989009035}\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.7s finished\n",
      "\n",
      " 71%|███████▏  | 5/7 [00:07<00:03,  1.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6103603603603603\n",
      "Best parameters: {'max_depth': 5, 'criterion': 'entropy', 'min_samples_split': 20}\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.1min finished\n",
      "\n",
      " 86%|████████▌ | 6/7 [02:12<00:22, 22.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.8333333333333333\n",
      "Best parameters: {'max_depth': 13, 'criterion': 'entropy', 'max_features': 'auto', 'min_samples_split': 20}\n",
      "Fitting 10 folds for each of 135 candidates, totalling 1350 fits\n"
     ]
    }
   ],
   "source": [
    "parameter_tuning_all(p229, C_range_num = 100, if_scaler = hp.if_scaler, \n",
    "                     if_remove_icd = hp.if_remove_icd, if_remove_sleep = 1, le_class = 0, if_remove_le = 1, if_save = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers removed: 45\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:   16.4s finished\n",
      "\n",
      " 14%|█▍        | 1/7 [00:16<01:38, 16.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7355650682149574\n",
      "Best parameters: {'penalty': 'l2', 'C': 0.030740559600262733}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   45.7s finished\n",
      "\n",
      " 29%|██▊       | 2/7 [01:02<02:35, 31.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7621423487146995\n",
      "Best parameters: {'gamma': 0.041666666666666664, 'kernel': 'rbf', 'C': 0.8192570603640273}\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    4.2s finished\n",
      "\n",
      " 71%|███████▏  | 5/7 [01:06<00:26, 13.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.677354944213609\n",
      "Best parameters: {'max_depth': 5, 'criterion': 'entropy', 'min_samples_split': 60}\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  5.2min finished\n",
      "\n",
      " 86%|████████▌ | 6/7 [06:18<01:03, 63.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7746460498686065\n",
      "Best parameters: {'max_depth': 15, 'criterion': 'entropy', 'max_features': 'auto', 'min_samples_split': 20}\n",
      "Fitting 10 folds for each of 135 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed: 31.4min finished\n",
      "\n",
      "100%|██████████| 7/7 [37:46<00:00, 323.72s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.76589419167611\n",
      "Best parameters: {'max_depth': 3, 'learning_rate': 0.005, 'subsample': 0.15, 'min_samples_leaf': 20}\n"
     ]
    }
   ],
   "source": [
    "parameter_tuning_all(p229, C_range_num = 100, if_scaler = hp.if_scaler, \n",
    "                     if_remove_icd = hp.if_remove_icd, if_remove_sleep = 1, le_class = None, if_remove_le = 1, if_save = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603351955307262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hp/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "JJ.ensemble_model(X_train, y_train, X_test, y_test, p231, if_save = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers removed: 19\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:   11.9s finished\n",
      "\r",
      " 14%|█▍        | 1/7 [00:11<01:11, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6607585081923943\n",
      "Best parameters: {'C': 0.19517445578083695, 'penalty': 'l1'}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   27.6s finished\n",
      "\r",
      " 29%|██▊       | 2/7 [00:39<01:38, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6867889496195189\n",
      "Best parameters: {'C': 4.90241546749882, 'kernel': 'rbf', 'gamma': 0.03571428571428571}\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    3.6s finished\n",
      "\r",
      " 71%|███████▏  | 5/7 [00:43<00:17,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6311262313615518\n",
      "Best parameters: {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 8}\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  5.1min finished\n",
      " 86%|████████▌ | 6/7 [05:50<00:58, 58.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6664817143862415\n",
      "Best parameters: {'max_features': 'auto', 'min_samples_split': 30, 'criterion': 'entropy', 'max_depth': 16}\n",
      "Fitting 10 folds for each of 135 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed: 61.2min finished\n",
      "100%|██████████| 7/7 [1:07:02<00:00, 574.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6507336969013348\n",
      "Best parameters: {'learning_rate': 0.005, 'min_samples_leaf': 20, 'subsample': 0.2, 'max_depth': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_tuning_all(p222_1, C_range_num = 100, if_scaler = hp.if_scaler, if_remove_icd = hp.if_remove_icd, if_save = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
