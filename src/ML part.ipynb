{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hp/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/hp/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import operator\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from random import shuffle\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "#PLOT CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import pickle\n",
    "#matrix inverse\n",
    "from numpy.linalg import inv\n",
    "import jj_basic_fn as JJ\n",
    "from hyperparams import Hyperparams as hp\n",
    "from patient import patient\n",
    "import prep\n",
    "import plot_funcs\n",
    "import modules\n",
    "#default size of the graph\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "n_classifier = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hp/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/hp/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "p231, p222_1, p222_2, p222_3, p229 = modules.build_patients()\n",
    "pat_list = [p231, p222_1, p222_2, p222_3, p229]\n",
    "for pat in pat_list:\n",
    "    JJ.save_object(pat, '../patients/' + pat.id +'.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_rs = hp.col_rs\n",
    "col_es = hp.col_es\n",
    "col_le = hp.col_le\n",
    "\n",
    "p231, p222_1, p222_2, p222_3, p229 = \\\n",
    "pickle.load(open(hp.prepath_pat + \"231.p\", \"rb\" )),\\\n",
    "pickle.load(open(hp.prepath_pat + \"222_1.p\", \"rb\" )), \\\n",
    "pickle.load(open(hp.prepath_pat + \"222_2.p\", \"rb\" )), \\\n",
    "pickle.load(open(hp.prepath_pat + \"222_3.p\", \"rb\" )),\\\n",
    "pickle.load(open(hp.prepath_pat + \"229.p\", \"rb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>region_start_time</th>\n",
       "      <th>sleep</th>\n",
       "      <th>delta1</th>\n",
       "      <th>delta2</th>\n",
       "      <th>delta3</th>\n",
       "      <th>delta4</th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "      <th>theta3</th>\n",
       "      <th>...</th>\n",
       "      <th>all1</th>\n",
       "      <th>all2</th>\n",
       "      <th>all3</th>\n",
       "      <th>all4</th>\n",
       "      <th>i12</th>\n",
       "      <th>i34</th>\n",
       "      <th>epoch</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>if_stimulated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 05:42:50.025600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>696.474474</td>\n",
       "      <td>585.337654</td>\n",
       "      <td>179.407563</td>\n",
       "      <td>692.198432</td>\n",
       "      <td>453.077808</td>\n",
       "      <td>768.757884</td>\n",
       "      <td>164.028258</td>\n",
       "      <td>...</td>\n",
       "      <td>1603.706866</td>\n",
       "      <td>4619.270803</td>\n",
       "      <td>743.910832</td>\n",
       "      <td>1968.323736</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 05:44:47.011200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>833.779602</td>\n",
       "      <td>651.250164</td>\n",
       "      <td>164.036945</td>\n",
       "      <td>828.162406</td>\n",
       "      <td>568.359164</td>\n",
       "      <td>825.928353</td>\n",
       "      <td>181.207567</td>\n",
       "      <td>...</td>\n",
       "      <td>2100.923760</td>\n",
       "      <td>3793.897019</td>\n",
       "      <td>656.189079</td>\n",
       "      <td>1974.650835</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 06:24:09.014400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>203.235705</td>\n",
       "      <td>264.172585</td>\n",
       "      <td>105.114985</td>\n",
       "      <td>210.849406</td>\n",
       "      <td>285.520004</td>\n",
       "      <td>333.247015</td>\n",
       "      <td>108.969777</td>\n",
       "      <td>...</td>\n",
       "      <td>965.044443</td>\n",
       "      <td>2133.818411</td>\n",
       "      <td>361.454615</td>\n",
       "      <td>982.985999</td>\n",
       "      <td>68.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1.315205e+17</td>\n",
       "      <td>2017-10-09 10:57:08.035200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.641848</td>\n",
       "      <td>110.515245</td>\n",
       "      <td>70.882142</td>\n",
       "      <td>113.874863</td>\n",
       "      <td>246.154818</td>\n",
       "      <td>183.792996</td>\n",
       "      <td>109.708240</td>\n",
       "      <td>...</td>\n",
       "      <td>740.347446</td>\n",
       "      <td>580.039480</td>\n",
       "      <td>314.440540</td>\n",
       "      <td>709.004495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1.315211e+17</td>\n",
       "      <td>2017-10-10 05:02:15.014400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>986.767934</td>\n",
       "      <td>332.538069</td>\n",
       "      <td>143.791948</td>\n",
       "      <td>290.389210</td>\n",
       "      <td>624.991166</td>\n",
       "      <td>498.583798</td>\n",
       "      <td>111.804233</td>\n",
       "      <td>...</td>\n",
       "      <td>1954.085657</td>\n",
       "      <td>2637.690746</td>\n",
       "      <td>486.038681</td>\n",
       "      <td>1008.348372</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>1.315211e+17</td>\n",
       "      <td>2017-10-10 05:49:13.987200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.760449</td>\n",
       "      <td>171.131138</td>\n",
       "      <td>65.142623</td>\n",
       "      <td>320.504534</td>\n",
       "      <td>138.982599</td>\n",
       "      <td>563.006368</td>\n",
       "      <td>127.228414</td>\n",
       "      <td>...</td>\n",
       "      <td>571.632521</td>\n",
       "      <td>1472.511456</td>\n",
       "      <td>316.656703</td>\n",
       "      <td>1073.414247</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1.315211e+17</td>\n",
       "      <td>2017-10-10 05:59:23.020800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.699012</td>\n",
       "      <td>208.390401</td>\n",
       "      <td>39.528188</td>\n",
       "      <td>119.645249</td>\n",
       "      <td>196.736448</td>\n",
       "      <td>633.993093</td>\n",
       "      <td>73.222596</td>\n",
       "      <td>...</td>\n",
       "      <td>623.283484</td>\n",
       "      <td>1783.981643</td>\n",
       "      <td>201.155257</td>\n",
       "      <td>779.467423</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>1.315224e+17</td>\n",
       "      <td>2017-10-11 05:41:49.027200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>892.982169</td>\n",
       "      <td>213.389915</td>\n",
       "      <td>89.680107</td>\n",
       "      <td>311.030932</td>\n",
       "      <td>649.320535</td>\n",
       "      <td>377.638450</td>\n",
       "      <td>88.172255</td>\n",
       "      <td>...</td>\n",
       "      <td>2041.113198</td>\n",
       "      <td>1829.581805</td>\n",
       "      <td>412.015766</td>\n",
       "      <td>1105.758960</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1.315224e+17</td>\n",
       "      <td>2017-10-11 09:47:15.043200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.993069</td>\n",
       "      <td>106.881199</td>\n",
       "      <td>26.926312</td>\n",
       "      <td>55.914169</td>\n",
       "      <td>149.341963</td>\n",
       "      <td>111.237546</td>\n",
       "      <td>49.992485</td>\n",
       "      <td>...</td>\n",
       "      <td>498.437238</td>\n",
       "      <td>372.045348</td>\n",
       "      <td>179.645672</td>\n",
       "      <td>353.406801</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>1.315224e+17</td>\n",
       "      <td>2017-10-11 10:56:37.017600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.761414</td>\n",
       "      <td>84.211143</td>\n",
       "      <td>49.556652</td>\n",
       "      <td>64.207501</td>\n",
       "      <td>196.764906</td>\n",
       "      <td>219.796690</td>\n",
       "      <td>120.406283</td>\n",
       "      <td>...</td>\n",
       "      <td>459.578702</td>\n",
       "      <td>527.817519</td>\n",
       "      <td>243.161417</td>\n",
       "      <td>530.678009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>1.317872e+17</td>\n",
       "      <td>2018-08-14 03:54:57.974400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.685450</td>\n",
       "      <td>186.150067</td>\n",
       "      <td>247.556372</td>\n",
       "      <td>530.193752</td>\n",
       "      <td>281.346825</td>\n",
       "      <td>456.867931</td>\n",
       "      <td>138.189118</td>\n",
       "      <td>...</td>\n",
       "      <td>870.414487</td>\n",
       "      <td>1386.759897</td>\n",
       "      <td>582.005624</td>\n",
       "      <td>1303.718812</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>1.317872e+17</td>\n",
       "      <td>2018-08-14 03:57:30.988800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.720402</td>\n",
       "      <td>154.098863</td>\n",
       "      <td>66.905656</td>\n",
       "      <td>168.993628</td>\n",
       "      <td>125.509104</td>\n",
       "      <td>199.235483</td>\n",
       "      <td>106.434605</td>\n",
       "      <td>...</td>\n",
       "      <td>557.305078</td>\n",
       "      <td>783.483693</td>\n",
       "      <td>259.501554</td>\n",
       "      <td>776.582796</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:32:07.036800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.302667</td>\n",
       "      <td>204.060698</td>\n",
       "      <td>61.567870</td>\n",
       "      <td>129.473618</td>\n",
       "      <td>151.700226</td>\n",
       "      <td>238.357193</td>\n",
       "      <td>148.969649</td>\n",
       "      <td>...</td>\n",
       "      <td>443.982378</td>\n",
       "      <td>712.814881</td>\n",
       "      <td>397.080482</td>\n",
       "      <td>859.129712</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:34:48.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.442444</td>\n",
       "      <td>194.976844</td>\n",
       "      <td>69.401723</td>\n",
       "      <td>176.100460</td>\n",
       "      <td>336.441055</td>\n",
       "      <td>428.506186</td>\n",
       "      <td>327.548260</td>\n",
       "      <td>...</td>\n",
       "      <td>721.999008</td>\n",
       "      <td>1161.001016</td>\n",
       "      <td>562.501709</td>\n",
       "      <td>1613.027934</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:36:20.016000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.507380</td>\n",
       "      <td>120.821675</td>\n",
       "      <td>76.659557</td>\n",
       "      <td>140.764908</td>\n",
       "      <td>267.030774</td>\n",
       "      <td>305.850460</td>\n",
       "      <td>199.939818</td>\n",
       "      <td>...</td>\n",
       "      <td>865.972112</td>\n",
       "      <td>810.919200</td>\n",
       "      <td>453.282793</td>\n",
       "      <td>1415.648043</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:41:37.017599999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.315376</td>\n",
       "      <td>205.774419</td>\n",
       "      <td>209.640074</td>\n",
       "      <td>184.750419</td>\n",
       "      <td>265.558684</td>\n",
       "      <td>196.383871</td>\n",
       "      <td>186.935521</td>\n",
       "      <td>...</td>\n",
       "      <td>995.993473</td>\n",
       "      <td>792.212372</td>\n",
       "      <td>638.884219</td>\n",
       "      <td>947.195234</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:44:42.000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.279724</td>\n",
       "      <td>125.160093</td>\n",
       "      <td>74.616125</td>\n",
       "      <td>86.633713</td>\n",
       "      <td>203.093098</td>\n",
       "      <td>185.279175</td>\n",
       "      <td>260.777722</td>\n",
       "      <td>...</td>\n",
       "      <td>593.761982</td>\n",
       "      <td>667.285156</td>\n",
       "      <td>558.995745</td>\n",
       "      <td>1135.266314</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 17:56:29.961600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.858818</td>\n",
       "      <td>75.122268</td>\n",
       "      <td>30.789880</td>\n",
       "      <td>66.254857</td>\n",
       "      <td>393.952639</td>\n",
       "      <td>288.818356</td>\n",
       "      <td>78.739544</td>\n",
       "      <td>...</td>\n",
       "      <td>802.392769</td>\n",
       "      <td>794.033167</td>\n",
       "      <td>211.019935</td>\n",
       "      <td>581.492550</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 18:16:36.019200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.027158</td>\n",
       "      <td>80.026866</td>\n",
       "      <td>100.414808</td>\n",
       "      <td>167.994568</td>\n",
       "      <td>354.762262</td>\n",
       "      <td>295.805692</td>\n",
       "      <td>101.343177</td>\n",
       "      <td>...</td>\n",
       "      <td>798.585169</td>\n",
       "      <td>729.646856</td>\n",
       "      <td>292.490244</td>\n",
       "      <td>684.805982</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>1.317877e+17</td>\n",
       "      <td>2018-08-14 18:32:13.977600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>475.421437</td>\n",
       "      <td>416.388456</td>\n",
       "      <td>315.003093</td>\n",
       "      <td>476.676144</td>\n",
       "      <td>324.026765</td>\n",
       "      <td>398.041372</td>\n",
       "      <td>450.571041</td>\n",
       "      <td>...</td>\n",
       "      <td>1030.755040</td>\n",
       "      <td>1274.223165</td>\n",
       "      <td>1021.665186</td>\n",
       "      <td>1549.431259</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename             region_start_time  sleep      delta1  \\\n",
       "1633  1.315205e+17 2017-10-09 05:42:50.025600000  1.0    696.474474   \n",
       "1634  1.315205e+17 2017-10-09 05:44:47.011200000  1.0    833.779602   \n",
       "1635  1.315205e+17 2017-10-09 06:24:09.014400000  1.0    203.235705   \n",
       "1636  1.315205e+17 2017-10-09 10:57:08.035200000  0.0    112.641848   \n",
       "1637  1.315211e+17 2017-10-10 05:02:15.014400000  1.0    986.767934   \n",
       "1638  1.315211e+17 2017-10-10 05:49:13.987200000  1.0    136.760449   \n",
       "1639  1.315211e+17 2017-10-10 05:59:23.020800000  1.0    134.699012   \n",
       "1640  1.315224e+17 2017-10-11 05:41:49.027200000  1.0    892.982169   \n",
       "1641  1.315224e+17 2017-10-11 09:47:15.043200000  0.0    99.993069    \n",
       "1642  1.315224e+17 2017-10-11 10:56:37.017600000  0.0    77.761414    \n",
       "...            ...                           ...  ...          ...    \n",
       "2738  1.317872e+17 2018-08-14 03:54:57.974400000  1.0    264.685450   \n",
       "2739  1.317872e+17 2018-08-14 03:57:30.988800000  1.0    146.720402   \n",
       "2740  1.317877e+17 2018-08-14 17:32:07.036800000  0.0    92.302667    \n",
       "2741  1.317877e+17 2018-08-14 17:34:48.000000000  0.0    136.442444   \n",
       "2742  1.317877e+17 2018-08-14 17:36:20.016000000  0.0    232.507380   \n",
       "2743  1.317877e+17 2018-08-14 17:41:37.017599999  0.0    423.315376   \n",
       "2744  1.317877e+17 2018-08-14 17:44:42.000000000  0.0    87.279724    \n",
       "2745  1.317877e+17 2018-08-14 17:56:29.961600000  0.0    151.858818   \n",
       "2746  1.317877e+17 2018-08-14 18:16:36.019200000  0.0    173.027158   \n",
       "2747  1.317877e+17 2018-08-14 18:32:13.977600000  0.0    475.421437   \n",
       "\n",
       "          delta2      delta3      delta4      theta1      theta2      theta3  \\\n",
       "1633  585.337654  179.407563  692.198432  453.077808  768.757884  164.028258   \n",
       "1634  651.250164  164.036945  828.162406  568.359164  825.928353  181.207567   \n",
       "1635  264.172585  105.114985  210.849406  285.520004  333.247015  108.969777   \n",
       "1636  110.515245  70.882142   113.874863  246.154818  183.792996  109.708240   \n",
       "1637  332.538069  143.791948  290.389210  624.991166  498.583798  111.804233   \n",
       "1638  171.131138  65.142623   320.504534  138.982599  563.006368  127.228414   \n",
       "1639  208.390401  39.528188   119.645249  196.736448  633.993093  73.222596    \n",
       "1640  213.389915  89.680107   311.030932  649.320535  377.638450  88.172255    \n",
       "1641  106.881199  26.926312   55.914169   149.341963  111.237546  49.992485    \n",
       "1642  84.211143   49.556652   64.207501   196.764906  219.796690  120.406283   \n",
       "...         ...         ...         ...          ...         ...         ...   \n",
       "2738  186.150067  247.556372  530.193752  281.346825  456.867931  138.189118   \n",
       "2739  154.098863  66.905656   168.993628  125.509104  199.235483  106.434605   \n",
       "2740  204.060698  61.567870   129.473618  151.700226  238.357193  148.969649   \n",
       "2741  194.976844  69.401723   176.100460  336.441055  428.506186  327.548260   \n",
       "2742  120.821675  76.659557   140.764908  267.030774  305.850460  199.939818   \n",
       "2743  205.774419  209.640074  184.750419  265.558684  196.383871  186.935521   \n",
       "2744  125.160093  74.616125   86.633713   203.093098  185.279175  260.777722   \n",
       "2745  75.122268   30.789880   66.254857   393.952639  288.818356  78.739544    \n",
       "2746  80.026866   100.414808  167.994568  354.762262  295.805692  101.343177   \n",
       "2747  416.388456  315.003093  476.676144  324.026765  398.041372  450.571041   \n",
       "\n",
       "          ...               all1         all2         all3         all4   i12  \\\n",
       "1633      ...        1603.706866  4619.270803  743.910832   1968.323736  28.0   \n",
       "1634      ...        2100.923760  3793.897019  656.189079   1974.650835  34.0   \n",
       "1635      ...        965.044443   2133.818411  361.454615   982.985999   68.0   \n",
       "1636      ...        740.347446   580.039480   314.440540   709.004495   0.0    \n",
       "1637      ...        1954.085657  2637.690746  486.038681   1008.348372  26.0   \n",
       "1638      ...        571.632521   1472.511456  316.656703   1073.414247  61.0   \n",
       "1639      ...        623.283484   1783.981643  201.155257   779.467423   63.0   \n",
       "1640      ...        2041.113198  1829.581805  412.015766   1105.758960  28.0   \n",
       "1641      ...        498.437238   372.045348   179.645672   353.406801   20.0   \n",
       "1642      ...        459.578702   527.817519   243.161417   530.678009   0.0    \n",
       "...       ...               ...          ...          ...          ...   ...    \n",
       "2738      ...        870.414487   1386.759897  582.005624   1303.718812  33.0   \n",
       "2739      ...        557.305078   783.483693   259.501554   776.582796   25.0   \n",
       "2740      ...        443.982378   712.814881   397.080482   859.129712   20.0   \n",
       "2741      ...        721.999008   1161.001016  562.501709   1613.027934  41.0   \n",
       "2742      ...        865.972112   810.919200   453.282793   1415.648043  30.0   \n",
       "2743      ...        995.993473   792.212372   638.884219   947.195234   40.0   \n",
       "2744      ...        593.761982   667.285156   558.995745   1135.266314  13.0   \n",
       "2745      ...        802.392769   794.033167   211.019935   581.492550   31.0   \n",
       "2746      ...        798.585169   729.646856   292.490244   684.805982   29.0   \n",
       "2747      ...        1030.755040  1274.223165  1021.665186  1549.431259  40.0   \n",
       "\n",
       "       i34  epoch  label   id  if_stimulated  \n",
       "1633  16.0  0      True   229  False          \n",
       "1634  14.0  0      True   229  False          \n",
       "1635  27.0  0      True   229  False          \n",
       "1636  0.0   0      True   229  False          \n",
       "1637  20.0  0      True   229  False          \n",
       "1638  18.0  0      True   229  False          \n",
       "1639  19.0  0      True   229  False          \n",
       "1640  16.0  0      True   229  False          \n",
       "1641  15.0  0      True   229  False          \n",
       "1642  0.0   0      True   229  False          \n",
       "...   ...  ..       ...   ...    ...          \n",
       "2738  17.0  9      False  229  False          \n",
       "2739  11.0  9      False  229  False          \n",
       "2740  9.0   9      False  229  False          \n",
       "2741  25.0  9      False  229  False          \n",
       "2742  20.0  9      False  229  False          \n",
       "2743  25.0  9      False  229  False          \n",
       "2744  7.0   9      False  229  False          \n",
       "2745  20.0  9      False  229  False          \n",
       "2746  15.0  9      False  229  False          \n",
       "2747  22.0  9      False  229  False          \n",
       "\n",
       "[1115 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p229.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_tuning(pat, X_train, X_test, y_train, y_test, classifier, C_range_num = 30, if_save = 0,\n",
    "                     nfold = 10, if_show = 1):\n",
    "    #defs is a dictionary to initiate classifier with the parameters that don't need to be tuned\n",
    "    defs = {}\n",
    "    defs['classifier'] = classifier\n",
    "    \n",
    "    num_instances, num_features = X_train.shape[0], X_train.shape[1]\n",
    "    n_fold = 10\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    CV = skf.split(np.zeros(len(y_train)), y_train)\n",
    "    \n",
    "\n",
    "    if classifier==1:\n",
    "        clf_name = 'Logistic Regression'\n",
    "        defs['class_weight'] = 'balanced'\n",
    "        defs['max_iter'] = 200\n",
    "        C_range = 10 ** np.random.uniform(-2, 1, size = C_range_num)\n",
    "        tuned_params = dict(penalty=['l1','l2'], C=C_range)\n",
    "    elif classifier == 2: \n",
    "        clf_name = 'SVM'\n",
    "        defs['class_weight'] = 'balanced'\n",
    "        kernel_list = ['rbf']    \n",
    "        gamma_list = [2**i*1/num_features for i in range(1)]\n",
    "        #degree_list = [2,3,4,5]\n",
    "        C_range = 10 ** np.random.uniform(-3, 1, size = C_range_num)\n",
    "        tuned_params = dict(kernel=kernel_list,gamma = gamma_list, C=C_range)\n",
    "\n",
    "    elif classifier==3:\n",
    "        clf_name = 'Gaussian Naive Bayes classifier'\n",
    "        prr = np.ones(2) * (1.0/2)\n",
    "        defs['priors'] = prr\n",
    "        clf_try = JJ.clf_list(defs)\n",
    "        clf_try.fit(X_train, y_train)\n",
    "        pat.estimator[classifier] = clf_try\n",
    "        return\n",
    "\n",
    "    elif classifier==4:\n",
    "        clf_name = 'Linear Discriminant Analysis'\n",
    "        prr = np.ones(2) * (1.0/2)\n",
    "        defs['solver'] = 'eigen'  # 'svd', 'lsqr', 'eigen'\n",
    "        defs['shrinkage'] = 'auto'\n",
    "        defs['priors'] = prr\n",
    "        clf_try = JJ.clf_list(defs)\n",
    "        clf_try.fit(X_train, y_train)\n",
    "        pat.estimator[classifier] = clf_try\n",
    "        return\n",
    "    elif classifier == 5:\n",
    "        clf_name = 'decision tree'\n",
    "        mss_list = [5,10,20,40,60]\n",
    "        criterion_list = ['entropy']\n",
    "        max_depth_list = [3,4,5,8,12,18]\n",
    "        clf_name = 'decision tree'\n",
    "        tuned_params = dict(criterion=criterion_list, min_samples_split=mss_list, max_depth = max_depth_list)\n",
    "    elif classifier == 6:\n",
    "        clf_name = 'random forest'\n",
    "        defs['n_estimators'] = 600\n",
    "        mss_list = [20,25,30,40]\n",
    "        criterion_list = ['entropy']\n",
    "        max_depth_list = [12,13,14,15,16]\n",
    "        max_features_list = ['auto']\n",
    "        tuned_params = dict(criterion=criterion_list, min_samples_split=mss_list, max_depth = max_depth_list, max_features = max_features_list)\n",
    "    elif classifier == 7:\n",
    "        clf_name = 'gradient boosting'\n",
    "        defs['n_estimators'] = 2000\n",
    "        max_depth_list, subsample_list, learning_rate_list, min_samples_leaf_list = [1,2,3], [0.1,0.15,0.2, 0.3, 0.4], [0.02, 0.01,0.005], [10,20,30] \n",
    "        #params = {'n_estimators': 1200, 'max_depth': 3, 'subsample': 0.5,\n",
    "        #  'learning_rate': 0.01, 'min_samples_leaf': 10, 'random_state': 3}\n",
    "        tuned_params = dict(max_depth=max_depth_list, subsample = subsample_list,learning_rate = learning_rate_list, min_samples_leaf= min_samples_leaf_list)\n",
    "    \n",
    "        \n",
    "    clf_try = JJ.clf_list(defs)\n",
    "    \n",
    "    clf_grid = GridSearchCV(clf_try,\n",
    "                            param_grid=tuned_params,\n",
    "                            cv=CV,\n",
    "                            scoring = 'roc_auc',\n",
    "                            verbose=1,\n",
    "                           return_train_score = True)\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    print('Best score for validations set: {}'.format(clf_grid.best_score_))\n",
    "    print('Best parameters: {}'.format(clf_grid.best_params_))\n",
    "\n",
    "    clf_best = clf_grid.best_estimator_\n",
    "\n",
    "    y_pred = clf_best.predict(X_test)\n",
    "    df = pd.DataFrame(clf_grid.cv_results_)\n",
    "    if if_show:\n",
    "        JJ.show_result(y_pred, y_test, df, clf_name, if_save = if_save)\n",
    "    \n",
    "    if if_save:\n",
    "        pat.result[classifier] = df\n",
    "        pat.estimator[classifier] = clf_best\n",
    "        pat.score[classifier] = clf_grid.best_score_\n",
    "        pat.params[classifier] = clf_grid.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n",
      "Best score for validations set: 0.7540759970984683\n",
      "Best parameters: {'C': 0.018666999416881786, 'penalty': 'l2'}\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:   46.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>{'C': 0.018666999416881786, 'penalty': 'l2'}</td>\n",
       "      <td>0.754076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>{'C': 0.01960072858125023, 'penalty': 'l2'}</td>\n",
       "      <td>0.753836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>{'C': 0.023034204166617975, 'penalty': 'l2'}</td>\n",
       "      <td>0.753650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>{'C': 0.028052932448207616, 'penalty': 'l2'}</td>\n",
       "      <td>0.753644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>{'C': 0.031173195602083075, 'penalty': 'l2'}</td>\n",
       "      <td>0.753642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'C': 0.03312254656438778, 'penalty': 'l2'}</td>\n",
       "      <td>0.753515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>{'C': 0.014965876497545138, 'penalty': 'l2'}</td>\n",
       "      <td>0.753071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>{'C': 0.01509348876676557, 'penalty': 'l2'}</td>\n",
       "      <td>0.753070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>{'C': 0.014800372466610662, 'penalty': 'l2'}</td>\n",
       "      <td>0.753067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>{'C': 0.014621364324401464, 'penalty': 'l2'}</td>\n",
       "      <td>0.753003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>{'C': 0.018666999416881786, 'penalty': 'l1'}</td>\n",
       "      <td>0.698850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>{'C': 0.01509348876676557, 'penalty': 'l1'}</td>\n",
       "      <td>0.682867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>{'C': 0.014965876497545138, 'penalty': 'l1'}</td>\n",
       "      <td>0.681871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>{'C': 0.014800372466610662, 'penalty': 'l1'}</td>\n",
       "      <td>0.681290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>{'C': 0.014621364324401464, 'penalty': 'l1'}</td>\n",
       "      <td>0.680937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>{'C': 0.013002342852650676, 'penalty': 'l1'}</td>\n",
       "      <td>0.675773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>{'C': 0.012890487059150595, 'penalty': 'l1'}</td>\n",
       "      <td>0.675486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>{'C': 0.012236769998540823, 'penalty': 'l1'}</td>\n",
       "      <td>0.674019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'C': 0.010907874912711172, 'penalty': 'l1'}</td>\n",
       "      <td>0.670309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>{'C': 0.010423236037575091, 'penalty': 'l1'}</td>\n",
       "      <td>0.666071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score\n",
       "155  {'C': 0.018666999416881786, 'penalty': 'l2'}  0.754076       \n",
       "113  {'C': 0.01960072858125023, 'penalty': 'l2'}   0.753836       \n",
       "73   {'C': 0.023034204166617975, 'penalty': 'l2'}  0.753650       \n",
       "133  {'C': 0.028052932448207616, 'penalty': 'l2'}  0.753644       \n",
       "79   {'C': 0.031173195602083075, 'penalty': 'l2'}  0.753642       \n",
       "29   {'C': 0.03312254656438778, 'penalty': 'l2'}   0.753515       \n",
       "69   {'C': 0.014965876497545138, 'penalty': 'l2'}  0.753071       \n",
       "63   {'C': 0.01509348876676557, 'penalty': 'l2'}   0.753070       \n",
       "51   {'C': 0.014800372466610662, 'penalty': 'l2'}  0.753067       \n",
       "185  {'C': 0.014621364324401464, 'penalty': 'l2'}  0.753003       \n",
       "..                                            ...       ...       \n",
       "154  {'C': 0.018666999416881786, 'penalty': 'l1'}  0.698850       \n",
       "62   {'C': 0.01509348876676557, 'penalty': 'l1'}   0.682867       \n",
       "68   {'C': 0.014965876497545138, 'penalty': 'l1'}  0.681871       \n",
       "50   {'C': 0.014800372466610662, 'penalty': 'l1'}  0.681290       \n",
       "184  {'C': 0.014621364324401464, 'penalty': 'l1'}  0.680937       \n",
       "84   {'C': 0.013002342852650676, 'penalty': 'l1'}  0.675773       \n",
       "196  {'C': 0.012890487059150595, 'penalty': 'l1'}  0.675486       \n",
       "198  {'C': 0.012236769998540823, 'penalty': 'l1'}  0.674019       \n",
       "34   {'C': 0.010907874912711172, 'penalty': 'l1'}  0.670309       \n",
       "90   {'C': 0.010423236037575091, 'penalty': 'l1'}  0.666071       \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAJCCAYAAACyMW3lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcjfX///HnNWcWzEJTiOwZIRGm0cKQSISxk736tPCh\nRtljLDOSJdl+ZalPaRiSCJXKVhIxFVlKH42QmCFjmcWY5Vy/Pz5fZ8gyLplzZs553Lud221c5zrv\n63WdyafX53m9r/dlmKZpCgAAAJDk5eoCAAAAUHDQHAIAAMCB5hAAAAAONIcAAABwoDkEAACAA80h\nAAAAHGgOgb/JycnRu+++qw4dOigiIkKtWrXSlClTlJmZ+Y/G7Nevn1q0aKGFCxda/vzu3bv1wgsv\n3PDxb7aUlBT17t37qu9HRETo7Nmz1z3e8uXL1aRJEz399NM3XNOsWbM0fvz4G/78373yyivasmXL\nNfcZNWqU9uzZc937X2zWrFm6//77FRERoYiICLVt21ZNmzbVxIkTVVBXGHvmmWf022+/uboMAPnM\nYJ1D4FKjR4/WmTNnNGHCBAUGBio9PV2DBw+Wv7+/pkyZckNjHj16VC1atNDOnTtls9lucsXOd+TI\nEbVp00Y7duy4KeP17t1bHTt2VERExA2PMWvWLJ06dUpRUVE3pabr0bRpU82YMUP33HOP5c9eqd4z\nZ86obdu2iomJUaNGjW5mqQBw3bxdXQBQkPzxxx9avXq1Nm/erICAAElSsWLFNG7cOEcjlJKSonHj\nxmnfvn0yDEONGjXSSy+9JG9vb91zzz169tln9e233+r48ePq3bu3OnXqpH/961/Kzs5Whw4dNGvW\nLDVv3lxbt25VcHCwJOmuu+7S1q1b5efnpxEjRujQoUPy8vLS3XffrfHjxys+Pl7R0dH65JNPLB+/\nb9++l53nPffco759++qrr75SamqqhgwZos8//1z//e9/VapUKc2ZM0fFihXTsmXL9MEHHygrK0tn\nzpzRM888o+7du2vEiBHKyMhQRESEli9frjp16uiRRx7Rvn37NHXqVHXq1Elbt25VXFycvvnmG8XF\nxSk5OVnt27fX1KlTdf/99ztqefXVV7V7924dOXJEp06dUseOHa96frVq1brkONfblH3//feaPHmy\nzp07Jx8fH0VGRio8PFw5OTmaPHmyNmzYoMDAQNWuXVsJCQmKjY1Vr1691KNHDzVr1kzR0dH68ccf\n5ePjo3LlymnixImaN2+ejh8/rsGDB2vy5MmaOnWqevTooccee0wbN27U9OnTZbfbHf/+VK9ePc86\n//rrL2VkZKh48eKSpISEBE2YMEGnT59WTk6OevXqpU6dOkmS5s2bp2XLlsnf31+hoaFav369NmzY\noOHDh+v06dP6448/1KRJE7344ouaOnWq4uPjlZOTo5o1a2rUqFEKCAhQXFyclixZIh8fH/n5+Wn8\n+PGqWrXqVbdf3Ax/8MEHio2NlZeXl2677TaNHj1alStX1vDhwxUQEKBff/1ViYmJqlKliqZNmyZ/\nf//r+l0BKABMAA6ff/652bFjx2vuM3ToUDM6Otq02+3m+fPnzaeeesqcO3euaZqmWa1aNTM2NtY0\nTdPcvXu3WatWLTMjI8P8448/zHvvvdcxRrVq1cyTJ09e9ucVK1aYTz31lGmappmdnW2+8sor5sGD\nB83vvvvOfPzxx2/4+H9XrVo1c8GCBaZpmubcuXPNunXrmomJiWZOTo7Zvn17c9WqVWZqaqrZpUsX\nMzk52TRN09yxY4fjHK50PitWrLjsfLKzs80ePXqYc+fONfv06WO+9dZbV/xOe/bsaa5Zs+a6zu/i\n41xs5syZ5rhx4y7bnpycbD7wwAPmzp07TdM0zf/+979mWFiYefjwYXPx4sVmjx49zIyMDMexevbs\neUlN8fHx5mOPPWba7XbTNE1z8uTJ5g8//GCapmk+/PDD5q5duy7Z/8SJE2b9+vXNn3/+2TRN0/zi\niy/Mp59++or1NmjQwGzbtq356KOPmmFhYWbfvn0d30NWVpbZqlUrc8+ePaZpmubZs2fNli1bmjt2\n7DA3bdpktmjRwjxz5oxpt9vNESNGmA8//LBpmqY5bNgws0+fPo7jzJo1y3zttdcc9b/++uvmmDFj\nzOzsbPPuu+82k5KSTNM0zRUrVphLliy56vaLz3fLli1ms2bNHP8Of/TRR2bLli1Nu91uDhs2zOza\ntat5/vx5MzMz02zXrp25bNmyK/7OABRMzDkELuLl5SW73X7NfTZt2qSePXvKMAz5+vqqW7du2rRp\nk+P9Rx55RJJ09913KzMzU+np6dd9/Pr16+u3335Tr169NG/ePPXp00cVK1bMl+O3aNFCklShQgVV\nq1ZNpUuXlpeXl8qVK6czZ87I399fc+bM0ddff63p06drzpw51zyX0NDQy7bZbDZNmTJF8+fPl2EY\neu655/L8DvI6vysd51p27dqlChUqqE6dOpKkkJAQ1atXT9u3b9fXX3+tiIgI+fn5ydfXV127dr3s\n89WqVZPNZlPnzp01ffp0tWjRQvXq1bvq8X788UeFhISoRo0akqRHH31Ub7/99hX3bdWqlVauXKnV\nq1fr0Ucf1blz5xQeHi5JOnjwoA4fPqyRI0cqIiJCPXv2VEZGhn7++Wd9/fXXeuyxxxQUFCTDMNSj\nR49Lxq1fv77j56+++kobNmxQu3btFBERoXXr1ikhIUE2m02PPfaYunXrpvHjxyswMFCdOnW66vaL\nffPNN2rVqpUj+e7QoYOSkpJ05MgRSVKjRo3k6+srHx8fVatWTWfOnLnm7whAwUJzCFykdu3aOnDg\ngFJTUy/ZnpSUpGeffVYZGRmXNY92u13Z2dmOP/v5+UmSDMOQpDxvLrj4Rpfy5ctr7dq1evbZZ5Wa\nmqonn3xSn3/++WXHuxnH9/HxueLPFyQmJqpdu3b6888/Vb9+fUVGRl7zPIoVK3bF7UePHpWfn58O\nHTp0XTep5HV+VzvO9Y4n/e87yc7Olrf3pTNrvLwu/5/EoKAgrVy5UsOGDZPNZlNkZKTee++9qx7P\nZrM5vvsLx9q3b981a/T19dXo0aOVlpbmmNeak5PjOPaF19KlS9WxY0d5e3tf8nv9+zzWi78ju92u\nkSNHOsb48MMPNWPGDEnS1KlTNWfOHFWoUEHz58/XgAEDrrn94nP6uwvfqSQVKVLEsd0wjAJ7gw2A\nK6M5BC5SunRptWnTRiNHjnQ0iKmpqRo7dqxKlCihIkWKqGHDhlq0aJFM01RmZqaWLl2qBx980NJx\ngoODtXv3bknS2rVrHdvj4uI0YsQINWzYUEOGDFHDhg21f//+Sz57M45/Pfbs2aPg4GD1799fjRo1\n0saNGyX9r2nx9vZWTk5Onv/RP3v2rIYMGaJJkyapdevWeuWVV/I87s0+vzp16uj333/Xrl27JEn7\n9+9XfHy8wsLC1LhxY61atUqZmZnKzs7WihUrLvv8xo0b1bdvX9WtW1cDBw5Uu3btHM2ezWa7pHG9\ncLyEhATH7239+vUaMmRInnX6+vpqzJgx+uCDD7R3715VrlxZfn5+WrlypSTp2LFjat26tfbs2aPG\njRvryy+/VEpKiiRp2bJlVx33wveZmZkpu92u0aNHa9q0aUpOTlbjxo1VokQJ9e3bV5GRkfr111+v\nuv3vY3722WdKTk6WJH300UcqUaLEZSk3gMKJG1KAvxkzZozefPNNdevWTTabTZmZmWrWrJkGDhwo\n6X/Ll8TExKhNmzbKyspSo0aN9Pzzz1s6xqhRozR+/HgFBQXpwQcfVMmSJSVJ7dq10/bt29WqVSsV\nLVpUZcuWVe/evS9Jnm7G8a/HQw89pGXLlumxxx5T0aJFVbt2bQUHB+vQoUOqWLGiatasqZYtW2rx\n4sXXPM8mTZrooYce0n333adOnTpp0aJFl10G/ftnbvT8li5dekmDd9ddd2nJkiWaMWOGoqOjlZGR\nIcMwNHHiRFWuXFkVK1bU77//rnbt2qlYsWIqV66cihYtesmY4eHh2rRpk1q3bq1ixYqpePHiio6O\nliQ1a9ZMgwYNUkxMjGP/2267TVOnTtWwYcOUk5OjgIAAvfHGG9dVf2hoqNq0aaPo6GgtXrxYb775\npiZMmKC3335b2dnZevHFFx2XjLt06aKuXbuqSJEiCgkJuazuC/r3769Jkyapffv2ysnJUY0aNRw3\njfTr1099+/ZVkSJFZLPZFBMTo+Dg4Ctuv9hDDz2kvn37qk+fPrLb7QoODtbcuXOvmLwCKHxYygaA\nx9q8ebNOnjzpWEInJiZGfn5+15X0udLu3bu1Y8cOx1qT7777rn766SdNnz7dxZUBcAc0hwA8VlJS\nkoYPH66TJ08qJydH1atX19ixYxUYGOjq0q4pNTVVI0eO1IEDB2QYhsqUKaPo6GiVLl3a1aUBcAM0\nhwAAAHBggggAAAAcaA4BAADgQHMIAAAAB7dayqZo3QF57wS38/2HIxXa+VVXlwEXWL802tUlwEXu\nrRCknYfzXlQd7ufBkFtcXYLT+o1zO2Y75Th/R3KIQu/uqmVdXQIAJyvmZ8t7JwA3xK2SQwAAgHxn\nuHe25t5nBwAAAEtIDgEAAKwwDFdXkK9IDgEAAOBAcggAAGAFcw4BAADgKUgOAQAArGDOIQAAADwF\nySEAAIAVzDkEAACApyA5BAAAsII5hwAAAPAUJIcAAABWMOcQAAAAnoLkEAAAwArmHAIAAMBTkBwC\nAABYwZxDAAAAeAqSQwAAACuYcwgAAABPQXIIAABgBXMOAQAA4ClIDgEAAKxgziEAAAA8BckhAACA\nFcw5BAAAgKcgOQQAALCC5BAAAACeguQQAADACi/uVgYAAICHIDkEAACwgjmHAAAA8BQkhwAAAFbw\nhBQAAAB4CpJDAAAAK5hzCAAAAE9BcggAAGAFcw4BAADgKUgOAQAArGDOIQAAADwFySEAAIAVzDkE\nAACApyA5BAAAsII5hwAAAPAUJIcAAABWMOcQAAAAnoLkEAAAwArmHAIAAMBTkBwCAABYwZxDAAAA\neAqSQwAAACuYcwgAAABPQXIIAABgBckhAAAAPAXJIQAAgBXcrQwAAABPQXMIAABgheHlnNd1+Omn\nn9SrVy9J0qFDh/TEE0+oe/fuGjNmjOx2uyRp6dKl6tChg7p06aKNGzfmOSbNIQAAQCE0f/58jRo1\nSufPn5ckTZw4UZGRkYqLi5Npmlq/fr1OnDih2NhYLVmyRO+8846mTZumzMzMa45LcwgAAGCFYTjn\nlYcKFSpo1qxZjj/v3btXYWFhkqTw8HBt2bJFu3btUt26deXr66vAwEBVqFBB+/btu+a4NIcAAACF\nUIsWLeTtnXtvsWmaMv6vqfT391dKSopSU1MVGBjo2Mff31+pqanXHJe7lQEAAKwooOscennl1pWW\nlqagoCAFBAQoLS3tku0XN4tXHCffKgQAAIDT1KxZU9u2bZMkbdq0SaGhoapdu7Z++OEHnT9/Xikp\nKUpISFC1atWuOQ7JIQAAgBUFdJ3DYcOGafTo0Zo2bZqqVKmiFi1ayGazqVevXurevbtM09SgQYPk\n5+d3zXFoDgEAAAqpcuXKaenSpZKkypUra+HChZft06VLF3Xp0uW6x6Q5BAAAsMAooMnhzcKcQwAA\nADiQHAIAAFhAcggAAACPQXIIAABghXsHhySHAAAAyEVyCAAAYAFzDgEAAOAxSA4BAAAscPfkkOYQ\nAADAAndvDrmsDAAAAAeSQwAAAAtIDgEAAOAxSA4BAACscO/gkOQQAAAAuUgOAQAALGDOIQAAADwG\nySEAAIAFJIcAAADwGCSHAAAAFpAcAgAAwGOQHAIAAFhAcggAAACPQXIIAABghXsHhySHAAAAyEVy\nCAAAYAFzDgEAAOAxSA4BAAAsIDkEAACAxyA5BAAAsIDkEAAAAB6D5BAAAMAK9w4OSQ4BAACQi+QQ\nAADAAuYcAgAAwGOQHAIAAFhAcggAAACPQXIIAABgAckhAAAAPAbJIQAAgAUkhwAAAPAYJIcAAABW\nuHdwSHIIAACAXCSHAAAAFjDnEAAAAB6D5BAAAMACkkMAAAB4DJJDAAAAC0gOAQAA4DFIDgEAAKxw\n7+CQ5BAAAAC5SA4BAAAsYM4hAAAAPAbNIQqNeeN6KrLXI5dsK1e6hCTp1hL+l+3fO+J+LZv+nFNq\nA5C/Nq39VM3rVpAkpaacVadOndTz8QfVo+X9Wjhvhourg6cxDMMpL1ehOUSBd1fl0lozd6A6Nq93\nyfburcO07j+DLtv/lqBimvlKN00b1tnto3/AE/xxMEGzJ0XJNE1J0vzpr6pcuXJa+OkWvf3Req1Y\n/B/t2bHdxVUC7oPmEAXe813C9f6q7/TR2h8d28qULK62TWqr3cC3Ltu/46P1lHjijEa8scKZZQLI\nBxnn0jV+8HMaOCLGsS1y1ERNnTpVknTyRJKyMjPlHxjkqhLhgdw9OeSGFBR4gyZ9KEl6OOwux7Zj\nJ86o2+C3r7j/28s2S5J6tmmQ/8UByFeTR7+kiG59VfWuux3bDMOQt7e3xg1+Tl99vkrhzR9Xhcoh\nLqwScC+FIjlMSEhQr169XF0GAMCJli96RzZvm1p36nnF98dMnatPt+3X2TOn9O7syU6uDp6M5BAA\nABf4bPliZWSkq0/bcGVnZep8xjn1aRuurn37qVKvdpKKqph/gJq17qivv1jt6nIBt5FvzWFGRoaG\nDh2q48ePq0yZMoqPj9e8efMUHR0tm80mPz8/RUdHq2zZsvrPf/6jTz/9VN7e3goNDdWQIUN0/Phx\nDR48WKZpqmTJkvlVJgCggHr7o3WOn48dOaxerR/SglWbNHHkQI078JN6vzxRWVmZ2vDZx7rvoSau\nKxSex83vdTTMC7d/3WQLFixQUlKShg4dqoSEBLVu3Vo1atTQhAkTVKNGDa1bt06rVq3Sv//9b40a\nNUpxcXHy9vbWwIED1bFjR33zzTeqXr26unTpos8++0yLFy9WbGzsNY+597ejurtq2fw4HQCACx08\neFC1atVSamqqTp8+reeff1579uyRYRhq166dxo0bJy+vQjFTCv/Alv2n9GDILa4uQ5UHfeqU4/z+\nxuNOOc7f5VtymJCQoPDwcEnSnXfeqeDgYB0/flw1atSQJN133316/fXXdeDAAdWpU0c+Pj6SpNDQ\nUO3fv18HDx5Uly5dJEn16tXT4sWL8zxmaOdX8+lsUJCd2zFbResOcHUZcIH1S6NdXQKcpri+3PGH\ntuw/JUlasmSJ42dJ+i7hjKsKgwdy92XS8u3/ZlWrVk07duyQJB0+fFinTp1SqVKltG/fPklSfHy8\nKlWqpCpVqmjXrl3Kzs6WaZqKj49X5cqVdeeddzo+v3v37vwqEwAAABfJt+SwU6dOGj58uHr06KGy\nZcvKz89PMTExio6OlmmastlsevXVV1W+fHm1bNlSTzzxhOx2u+rXr69mzZqpfv36GjJkiD777DOV\nK1cuv8oEAACwxN2Tw3xrDn/++Wd16tRJDRs21MGDB7Vjxw7VrFlTixYtumzfJ598Uk8++eQl24KD\ng/XOO+/kV3kAAAC4gnxrDsuXL6+XXnpJs2fPVnZ2tqKiovLrUAAAAE7j5sFh/jWHJUuWzPPuYgAA\nABQsLIINAABggbvPOWRRKAAAADiQHAIAAFjg5sEhySEAAABykRwCAABYwJxDAAAAeAySQwAAAAvc\nPDgkOQQAAEAukkMAAAALvLzcOzokOQQAAIADySEAAIAFzDkEAACAxyA5BAAAsIB1DgEAAOAxSA4B\nAAAscPPgkOQQAAAAuUgOAQAALGDOIQAAADwGySEAAIAFJIcAAADwGCSHAAAAFrh5cEhyCAAAgFwk\nhwAAABYw5xAAAAAeg+QQAADAAjcPDkkOAQAAkIvkEAAAwALmHAIAAMBjkBwCAABY4ObBIckhAAAA\ncpEcAgAAWMCcQwAAAHgMkkMAAAAL3Dw4JDkEAABALpJDAAAAC5hzCAAAAI9BcggAAGBBQQgOs7Ky\nNHz4cP3555/y8vJSdHS0vL29NXz4cBmGoZCQEI0ZM0ZeXtZzQJpDAACAQubrr79Wdna2lixZom+/\n/VbTp09XVlaWIiMj1aBBA0VFRWn9+vVq3ry55bG5rAwAAGCBYRhOeV1L5cqVlZOTI7vdrtTUVHl7\ne2vv3r0KCwuTJIWHh2vLli03dH4khwAAABYUhMvKxYoV059//qmWLVvq1KlTmjNnjuLj4x1Npb+/\nv1JSUm5obJpDAACAQua9995Tw4YN9fLLL+vYsWPq06ePsrKyHO+npaUpKCjohsbmsjIAAIAFBeGy\nclBQkAIDAyVJxYsXV3Z2tmrWrKlt27ZJkjZt2qTQ0NAbOj+SQwAAgEKmb9++GjlypLp3766srCwN\nGjRItWrV0ujRozVt2jRVqVJFLVq0uKGxaQ4BAAAsKAhzDv39/TVjxozLti9cuPAfj81lZQAAADiQ\nHAIAAFjA4/MAAADgMUgOAQAALCA5BAAAgMcgOQQAALDAzYNDkkMAAADkIjkEAACwgDmHAAAA8Bgk\nhwAAABa4eXBIcggAAIBcJIcAAAAWMOcQAAAAHoPkEAAAwAI3Dw5JDgEAAJCL5BAAAMACLzePDkkO\nAQAA4EByCAAAYIGbB4ckhwAAAMhFcggAAGAB6xwCAADAY5AcAgAAWODl3sEhySEAAABykRwCAABY\nwJxDAAAAeAySQwAAAAvcPDgkOQQAAEAukkMAAAALDLl3dEhyCAAAAAeSQwAAAAtY5xAAAAAeg+QQ\nAADAAtY5BAAAgMcgOQQAALDAzYNDkkMAAADkIjkEAACwwMvNo0OSQwAAADiQHAIAAFjg5sEhySEA\nAABykRwCAABYwDqHAAAA8BgkhwAAABa4eXBIcggAAIBcJIcAAAAWsM4hAAAAPAbJIQAAgAXunRuS\nHAIAAOAiJIcAAAAWsM4hAAAAPAbJIQAAgAVe7h0ckhwCAAAgF8khAACABcw5BAAAgMe4anI4e/bs\na35wwIABN70YAACAgs7Ng0OSQwAAAOS6anJ4cTKYnp6uw4cPq1q1asrIyFCxYsWcUhwAAEBB4/Fz\nDrdu3aqIiAj1799ff/31l5o2barNmzc7ozYAAAA4WZ7N4bRp0xQXF6egoCCVKlVKCxcu1OTJk51R\nGwAAQIHjZTjn5bLzy2sHu92ukiVLOv5ctWrVfC0IAAAArpPnOoe33367Nm7cKMMwdPbsWS1atEhl\ny5Z1Rm0AAAAFjsfPORw/frxWr16tY8eOqVmzZvrll180fvx4Z9QGAAAAJ8szObz11ls1bdo0paam\nytvbW0WKFHFGXQAAAAWSe+eG19Ec/vrrrxo+fLiOHj0qSapSpYomTZqkChUq5HtxAAAAcK48m8Mx\nY8YoMjJSjRs3liStXbtWI0eO1MKFC/O9OAAAgILGy9PnHJ4/f97RGEpS8+bNlZqamq9FAQAAwDWu\nmhxeuIxcvXp1zZs3T506dZLNZtPq1asVGhrqtAIBAAAKEjcPDq/eHPbs2VOGYcg0TW3btk1Llixx\nvGcYhkaNGuWUAgEAAOA8V20ON2zY4Mw6AAAACgV3X+cwzxtSDhw4oLi4OKWnp8s0Tdntdh05ckSL\nFi1yRn0AAABwojxvSBk0aJCCgoL0yy+/qEaNGjp58qRCQkKcURsAAECBYxjOeblKnsmh3W7XCy+8\noOzsbNWsWVPdunVTt27dnFEbAAAAnCzP5LBo0aLKzMxUpUqVtHfvXvn6+ur8+fPOqA0AAKDA8TIM\np7xcdn557dC2bVs9//zzatKkiRYuXKh//etfKl26tDNqAwAAgJPleVm5Z8+eateunQICAhQbG6vd\nu3erYcOGzqgNAACgwHHzm5Wv3hzOnj37qh/69ddfNWDAgHwpCAAAAK6TZ3IIAACAXB67zmFhTAZP\nxV897YR743fvmb74OdHVJcCFTpzj5kggP5AcAgAAWJDn3byFnLufHwAAACy4ruYwPT1d+/btk2ma\nSk9Pz++aAAAACizDMJzycpU8m8OtW7cqIiJC/fv314kTJ9S0aVNt3rzZGbUBAADAyfJsDqdNm6a4\nuDgFBQWpVKlSWrhwoSZPnuyM2gAAAAocL8M5L5edX1472O12lSxZ0vHnqlWr5mtBAAAAcJ0871a+\n/fbbtXHjRhmGobNnz2rRokUqW7asM2oDAAAocFyZ6jlDnsnh+PHjtXr1ah07dkzNmjXTL7/8ovHj\nxzujNgAAADhZnsnhrbfeqmnTpjmjFgAAgALPY5+QckHTpk2v+CWsX78+XwoCAACA6+TZHMbGxjp+\nzs7O1tq1a5WZmZmvRQEAABRUHj/n8I477nC8KlasqH/9619at26dM2oDAACAk+WZHMbHxzt+Nk1T\n+/fv1/nzPOwcAAB4Jjefcph3czhz5kzHz4Zh6JZbbtFrr72Wr0UBAADANfJsDlu2bKnu3bs7oxYA\nAIACz8vNo8M85xzGxcU5ow4AAIBCwctJL1e5riek9O7dW3Xq1JGfn59j+4ABA/K1MAAAADhfns3h\nvffe64w6AAAACgU3v6p89eZwxYoVat++PQkhAACAB7nqJe3333/fmXUAAAAUCl6G4ZSXy87PZUcG\nAABAgXPVy8r79+/XI488ctl20zRlGAbPVgYAAB7JY+ccVqxYUfPmzXNmLQAAAHCxqzaHPj4+uuOO\nO5xZCwAAQIHn5ebJ4VXnHNarV8+ZdQAAAKAAuGpyGBUV5cw6AAAACgWPf3weAAAAPEeeT0gBAABA\nroISHM6dO1cbNmxQVlaWnnjiCYWFhWn48OEyDEMhISEaM2aMvLys54AkhwAAAIXMtm3btGPHDi1e\nvFixsbFKTEzUxIkTFRkZqbi4OJmmecPLDtIcAgAAWOBlOOd1LZs3b1a1atX073//W88//7yaNGmi\nvXv3KiwsTJIUHh6uLVu23ND5cVkZAACgkDl16pSOHj2qOXPm6MiRI+rXr5/jQSWS5O/vr5SUlBsa\nm+YQAADAAkOun3RYokQJValSRb6+vqpSpYr8/PyUmJjoeD8tLU1BQUE3NDaXlQEAAAqZ+vXr65tv\nvpFpmkrS8jv3AAAXlElEQVRKStK5c+f0wAMPaNu2bZKkTZs2KTQ09IbGJjkEAACwoCA8IeXhhx9W\nfHy8OnXqJNM0FRUVpXLlymn06NGaNm2aqlSpohYtWtzQ2DSHAAAAhdDQoUMv27Zw4cJ/PC7NIQAA\ngAUFITnMT8w5BAAAgAPJIQAAgAVGQXlESj4hOQQAAIADySEAAIAFzDkEAACAxyA5BAAAsMDNpxyS\nHAIAACAXySEAAIAFXm4eHZIcAgAAwIHkEAAAwALuVgYAAIDHIDkEAACwwM2nHJIcAgAAIBfJIQAA\ngAVecu/okOQQAAAADiSHAAAAFjDnEAAAAB6D5BAAAMAC1jkEAACAxyA5BAAAsIBnKwMAAMBjkBwC\nAABY4ObBIckhAAAAcpEcAgAAWMCcQwAAAHgMkkMAAAAL3Dw4JDkEAABALpJDAAAAC9w9WXP38wMA\nAIAFJIcAAAAWGG4+6ZDkEAAAAA4khwAAABa4d25IcggAAICLkBwCAABYwBNSAAAA4DFIDgEAACxw\n79yQ5BAAAAAXITkEAACwwM2nHJIcAgAAIBfJIQAAgAU8IQUAAAAeg+QQAADAAndP1tz9/AAAAGAB\nySEAAIAFzDkEAACAxyA5BAAAsMC9c0OSQwAAAFyE5BAAAMAC5hwCAADAY5AcAgAAWODuyZq7nx8A\nAAAsIDkEAACwgDmHAAAA8BgkhwAAABa4d25IcggAAICLkBwCAABY4OZTDkkOAQAAkIvkEAAAwAIv\nN591SHIIAAAAB5JDAAAAC5hzCAAAAI9BcggAAGCBwZxDAAAAeAqSQwAAAAuYcwgAAACPQXIIAABg\nAescAgAAwGOQHAIAAFjAnEMAAAB4DJJDAAAAC0gOAQAA4DFIDgEAACzgCSkAAADwGCSHAAAAFni5\nd3BIcwgAAGAFl5UBAADgMUgOAQAALGApGwAAAHgMkkMAAAALmHMIAAAAj0FyCAAAYIG7L2VDcggA\nAAAHmkMUKosXLVRYvTpqUP9eNWn0oH74/nvl5OTo5UEvqk6t6rq7elXNnzvH1WUCuMm+27BGTzwY\nIklKOXNKXbt2Vf+2DfVS1+b6JO4dF1cHT2M46R9X4bIyCo3//vqrRg4foi3bf1SZMmX0+ZrP1K1L\nB40YPlwJv+3XDzv3KCUlRU0aPaB769bTfWFhri4ZwE1w9NABvTdtvEy7XZL0nyljVLlkoGat+Fp2\ne44mRj6p0ndU0H2Nm7u4UsA9kByi0PDz89Obc99WmTJlJEn16ocqKTFRH374oXr1eVLe3t665ZZb\n1LlLNy2OW+jiagHcDOfPpeuNkQP01OCxjm0JP+9Sr169ZLPZ5OPjq9BGzbRl3SeuKxIexzCc83IV\nmkMUGhUrVVLLVo9LkkzT1LDBL+nxNm117NgxlStX3rHfHXeU059/HnFVmQBuojejh6pFp16qGFLT\nsS3knnqKjY1VdlaWzqWnaeu6T3XqRJILqwTcC80hCp20tDT1eKKLEhJ+01tz35b9/y41Xcxms7mg\nMgA302cfvCebzVvN2j9xyfYnXx4jwzD0Utfmem3QU6rzQLi8fXxdVCU8keGkl6s4vTlcvny5pk6d\navlzDz30UD5Ug8Lm8OHDerjRg7LZbPpi3UaVKFFCFSpUUGLiMcc+R4/+qTvuKOfCKgHcDBtXfqDf\n9u5UZJdmih7QQ5nnMxTZpZnOpaVo8uTJmrn8K42b+4G8DC+VqVDJ1eUCboPkEIVGcnKyHn2ksSLa\nd1DsoiUqWrSoJCkiIkLvv/cfZWdn6/Tp0/pw6RK1jWjn4moB/FNT4tZo5vKvNH3pOo2evUi+fkU0\nfek6ff7h+4qKipIknT55Ql8uX6Twlh1cXC08iZdhOOXlKi65W3nnzp3q06ePUlNTNXDgQGVkZGjR\nokXKzs6WYRiaPXu2ihcvrtGjR+u3335T+fLllZmZ6YpSUYDMn/uW/jh8WKs+XqFVH69wbP/yyy/0\n6/4EhdWvo8zMTD39zHNqFN7YhZUCyE+dnn5BSyYN1gsdmsg0TXV7/mWF1LrX1WUBbsMwTdN05gGX\nL1+uNWvWaN68eUpOTlbnzp3VpUsX9enTR0WLFlVUVJRCQ0Pl6+urtWvX6vXXX9fRo0f16KOPas+e\nPdcc2266/6rlAAB4qpW7EhVR+3ZXl6HvfjvtlOPcX7WEU47zdy5JDuvXry/DMHTrrbcqMDBQ3t7e\nGjZsmPz9/XXgwAHde++9Onr0qGrXri1JKlu2rGP5kmvJzMnvylEQFfGWMrJdXQVc4YufE11dAlwk\novbtWrmL3z+QH1wy53D37t2SpBMnTiglJUULFizQG2+8oZiYGPn5+ck0TVWtWlU7d+6UJCUlJSkp\niWUKAABAAeDmtyu7JDnMyMhQ7969lZ6ergkTJmjJkiXq2rWrvL29FRQUpOPHj6tDhw769ttv1blz\nZ5UtW1a33HKLK0oFAADwKE6fc5ifuLTombis7Lm4rOy5uKzsuQrCnMNtCWeccpwGdxZ3ynH+jqVs\nAAAA4OCSy8oAAACFlSufe+wMJIcAAABwIDkEAACwwM2DQ5JDAAAA5CI5BAAAsMLNo0OSQwAAADjQ\nHAIAAFhgOOmf63Hy5Ek1btxYCQkJOnTokJ544gl1795dY8aMkd1uv6HzozkEAAAohLKyshQVFaUi\nRYpIkiZOnKjIyEjFxcXJNE2tX7/+hsalOQQAALDAMJzzysukSZPUrVs3lSpVSpK0d+9ehYWFSZLC\nw8O1ZcuWGzo/mkMAAIBCZvny5QoODlajRo0c20zTlPF/XaW/v79SUlJuaGzuVgYAALCgINys/NFH\nH8kwDG3dulW//PKLhg0bpuTkZMf7aWlpCgoKuqGxaQ4BAAAKmUWLFjl+7tWrl8aOHaspU6Zo27Zt\natCggTZt2qT777//hsbmsjIAAIAVhpNeFg0bNkyzZs1S165dlZWVpRYtWtzQ6ZEcAgAAFGKxsbGO\nnxcuXPiPx6M5BAAAsOB61yAsrLisDAAAAAeSQwAAAAuuZw3CwozkEAAAAA4khwAAABa4eXBIcggA\nAIBcJIcAAABWuHl0SHIIAAAAB5JDAAAAC1jnEAAAAB6D5BAAAMAC1jkEAACAxyA5BAAAsMDNg0OS\nQwAAAOQiOQQAALDCzaNDkkMAAAA4kBwCAABYwDqHAAAA8BgkhwAAABawziEAAAA8BskhAACABW4e\nHJIcAgAAIBfJIQAAgBVuHh2SHAIAAMCB5BAAAMAC1jkEAACAxyA5BAAAsIB1DgEAAOAxSA4BAAAs\ncPPgkOQQAAAAuUgOAQAArHDz6JDkEAAAAA4khwAAABawziEAAAA8BskhAACABaxzCAAAAI9BcggA\nAGCBmweHJIcAAADIRXIIAABghZtHhySHAAAAcCA5BAAAsIB1DgEAAOAxSA4BAAAsYJ1DAAAAeAyS\nQwAAAAvcPDgkOQQAAEAukkMAAAAr3Dw6JDkEAACAA8khAACABaxzCAAAAI9BcggAAGAB6xwCAADA\nY5AcAgAAWODmwSHJIQAAAHKRHAIAAFjAnEMAAAB4DJJDAAAAS9w7OiQ5BAAAgAPJIQAAgAXMOQQA\nAIDHIDkEAACwwM2DQ5pDAAAAK7isDAAAAI9BcggAAGCB4eYXlkkOAQAA4EByCAAAYIV7B4ckhwAA\nAMhFcggAAGCBmweHJIcAAADIRXIIAABgAescAgAAwGOQHAIAAFjAOocAAADwGCSHAAAAVrh3cEhy\nCAAAgFwkhwAAABa4eXBIcggAAIBcJIcAAAAWsM4hAAAAPAbJIQAAgAWscwgAAACPQXIIAABgAXMO\nAQAA4DFoDgEAAOBAcwgAAAAH5hwCAABYwJxDAAAAeAySQwAAAAtY5xAAAAAeg+QQAADAAuYcAgAA\nwGOQHAIAAFjg5sEhySEAAABykRwCAABY4ebRIckhAAAAHEgOAQAALGCdQwAAAHgMkkMAAAALWOcQ\nAAAAHoPkEAAAwAI3Dw5JDgEAAJCL5BAAAMAKN48OSQ4BAADgQHIIAABggbuvc0hzCAAAUMhkZWVp\n5MiR+vPPP5WZmal+/fqpatWqGj58uAzDUEhIiMaMGSMvL+sXiWkOAQAALCgI6xyuWrVKJUqU0JQp\nU3T69Gm1a9dO1atXV2RkpBo0aKCoqCitX79ezZs3tzw2cw4BAAAKmccee0wvvviiJMk0TdlsNu3d\nu1dhYWGSpPDwcG3ZsuWGxnar5LCIW50NrOB375kiat/u6hLgQvz+4SoF4b85/v7+kqTU1FS98MIL\nioyM1KRJk2T8X6zp7++vlJSUGxqb5BAAAKAQOnbsmHr37q2IiAi1adPmkvmFaWlpCgoKuqFxaQ4B\nAAAKmb/++ktPPfWUhgwZok6dOkmSatasqW3btkmSNm3apNDQ0Bsa2zBN07xplQIAACDfxcTEaM2a\nNapSpYpj2yuvvKKYmBhlZWWpSpUqiomJkc1mszw2zSEAAAAcuKwMAAAAB5pDAAAAONAcwi0xWwLw\nDPxdB24+mkO4lfnz5+v777+XYRj8RwNwYxf+fhuGIbvd7uJqAPdCcwi3kZWVpeLFi2vmzJn6+eef\naRABN/b666+ra9eukiQvLy8aROAmojmEW8jJyZGPj4/at2+vUqVK6bXXXtOuXbtoEAE3NXjwYAUF\nBenll1+WRIMI3Ew0h3ALNptNpmlq+PDhqlChgsLCwjR16lQaRMDNXPi7nJqaqjvuuEPx8fF6+umn\nJdEgAjcLzSHcxldffaX09HS98MILGjBggFq3bq2YmBjt2bPH8axJAIWbYRhKS0tTZGSkGjRooE2b\nNikgIEDPPfecJF3y+DAAN4a/RSi0cnJyLvlzmTJlVK5cOSUlJUmSypUrp+Dg4Mv2A1D4XJwI+vj4\nKCgoSLfeeqskacaMGdq1a5diYmJcVR7gVrxdXQBwI+x2u2w2m+x2u2bOnClvb2/deeedOnjwoN57\n7z0FBATo22+/1dChQ1WnTh1XlwvgH7Db7fLy8lJycrJ+//13lS9fXnXr1tWPP/4owzCUnZ2thg0b\nqkePHq4uFXALPD4PhZZpmnruuedUo0YNBQQEyDRNFStWTLfccotSU1NVsWJF3X///a4uE8BNkJSU\npMGDB8vPz0+hoaEqU6aMzpw5o127dumvv/7S6NGjdeedd7q6TMAtkByi0DFNU4ZhaOfOnSpatKgG\nDRokSfr444+1c+dOjR071rUFArgpLiSG586d04QJE9SvXz/5+flpypQpatiwocLCwtS7d2+dPXtW\nQUFBri4XcBvMOUShcWHu4IWbS8qXL6/U1FStX79ekhQSEqLExEQlJydzdzLgBry8vJSRkaHjx4+r\nQYMGKlWqlD744AP16dNHmzdv1vr163X+/HkaQ+AmIzlEoXDxHMPo6GiVLl1amZmZ6tatmz755BNt\n375d27dvV2RkpIKDg11dLoB/YNGiRXrggQdUqlQpDRw4UCVLltS+ffuUnZ2t7t27q3jx4ipSpIj6\n9u0rPz8/V5cLuB3mHKLAu3BpyTRN9e/fX5UqVVLz5s31zjvvKCgoSM8++6x27dqlKlWq6J577nF1\nuQD+gZSUFL333ntKSUnR77//roiICLVs2VKDBg3S2rVrValSJRUvXlzjx49XtWrVXF0u4JZIDlGg\nXWgMJen48eMqVaqUhg0bJkm6/fbb9eabb6py5cqqXLmyK8sEcJMEBgaqR48e+uijj7Rr1y5VqlRJ\nNptNM2bM0NixY9WoUSPVqlVLt99+u6tLBdwWzSEKrJycHMeTT/r166fExETdcsstSk5OVnBwsA4d\nOqRDhw7pzJkzCgoKYqFrwE0EBwerc+fOys7O1ldffSVfX18lJibqwIEDGjFihIoUKeLqEgG3xmVl\nFGh2u11RUVEKDAzU999/r927d+vee+9V+/bttWTJEr300ktq1KiRq8sEkA+Sk5P10Ucfae3atSpR\nooSGDh2qqlWruroswO3RHKJAmzt3rhISEjR58mRlZ2frmWee0c8//6z58+fLMAzmGAJuLjk5WZ98\n8okeffRRLiUDTsJSNijQQkJCVKZMGSUnJ8vb21tPPPGEMjMztXLlShpDwAMEBwerR48eNIaAE9Ec\nokCrUaOGTp48qdWrV2vZsmVatWqV3nzzTZ04cUKnT592dXkAnMBms7m6BMCj0ByiQCtTpoyeeeYZ\nFS1aVD/88IN69+6tIkWKOJJEAABwczHnEIXG7t27tX37dn3xxReaMGGCQkJCXF0SAABuh+YQhca5\nc+f0+++/KzAwUOXLl3d1OQAAuCWaQwAAADgw5xAAAAAONIcAAABwoDkEAACAA80hgOty5MgR1apV\nSxEREWrXrp0ef/xxPfnkk0pMTLzhMZcvX67hw4dLkp555hklJSVddd+ZM2fq+++/tzT+XXfdddm2\nWbNmadasWdf8XNOmTXXkyJHrPs71jAkAhQXNIYDrVqpUKa1cuVIff/yxPv30U9WqVUvR0dE3Zez5\n8+erdOnSV30/Pj5eOTk5N+VYAICrYxVhADcsNDRUGzZskPS/tK127dr65ZdfFBcXp2+++UYLFiyQ\n3W7X3XffrTFjxsjPz08ff/yx3nrrLQUEBOiOO+5QsWLFHJ9///33VbJkSY0bN04//PCDfHx81L9/\nf2VmZmrPnj0aNWqUZs+erSJFimjs2LE6ffq0ihQpotGjR6tmzZo6cuSIhgwZovT0dNWpUyfP+hcu\nXKiVK1fq3LlzMgxD06dP15133ilJmj17tvbt2yc/Pz+NGzdO1atX119//aWoqCglJibKMAy9/PLL\nevDBB/PvCwYAFyA5BHBDsrKytGbNGtWrV8+xLTw8XF988YWSk5O1dOlSLVmyRCtXrtStt96qd955\nR0lJSZo6daoWLVqkDz74QGlpaZeNGxsbq/T0dK1Zs0bvvvuu/t//+39q1aqVatWqpZiYGN11110a\nNmyYhgwZohUrVig6OlqDBg2SJEVHR6tDhw5auXLlJXVdSWpqqtatW6fY2Fh98sknatasmeLi4hzv\nV6xYUR9//LH69+/vuPQ9YcIEdezYUcuXL9dbb72lqKgopaam3oyvEwAKDJJDANft+PHjioiIkCRl\nZmaqdu3aevnllx3vX0jrtm3bpkOHDqlLly6S/tdI1qxZUzt27FDdunV12223SZLatGmj77777pJj\nxMfHq0uXLvLy8lLJkiX16aefXvJ+Wlqa9uzZoxEjRji2paen69SpU9q+fbtef/11SVLbtm01atSo\nq55LQECAXn/9dX366ac6ePCgvvnmG9WoUcPxfufOnSVJjRs31pAhQ3T27Flt2bJFBw4c0MyZMyVJ\n2dnZ+uOPPyx8gwBQ8NEcArhuF+YcXo2fn58kKScnRy1btnQ0Z2lpacrJydHWrVtlt9sd+1/p+dh/\n33bo0CGVKVPG8We73S5fX99L6khMTFSJEiUkSRfW9TcMQ4ZhXLXWY8eOqVevXurZs6fCw8N12223\n6ZdffnG8b7PZLtnfx8dHdrtdCxYscBwrKSlJt912m9atW3fV4wBAYcNlZQA3XYMGDbR27VqdPHlS\npmlq7NixWrBggerXr6+ffvpJSUlJstvt+uyzzy777H333ac1a9bINE2dPHlSPXv2VGZmpmw2m3Jy\nchQYGKhKlSo5msNvv/1WPXr0kCQ9+OCDWrVqlSTpyy+/VGZm5lVr3L17typWrKi+ffuqTp062rRp\n0yU3vKxevVqStHbtWlWpUkVFixbV/fff77j0/Ntvv6lt27Y6d+7czfnSAKCAIDkEcNNVr15dAwYM\nUJ8+fWS321WjRg09++yz8vPz06hRo9S3b18VLVpUVatWveyz3bt3V0xMjNq2bStJGj16tAICAtSo\nUSONGTNGkyZN0pQpUzR27Fi9/fbb8vHx0RtvvCHDMBQVFaUhQ4ZoyZIluueee+Tv73/VGh966CEt\nXrxYrVq1kq+vr2rXrq39+/c73j948KAiIiLk7++v1157TZI0atQoRUVFqU2bNpKkyZMnKyAg4GZ+\ndQDgcjxbGQAAAA5cVgYAAIADzSEAAAAcaA4BAADgQHMIAAAAB5pDAAAAONAcAgAAwIHmEAAAAA40\nhwAAAHD4/0y/XMRPhH5zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22b96358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = modules.get_ml_data(p229, if_remove_icd = 0, if_remove_sleep=1)\n",
    "parameter_tuning(p229,X_train, X_test, y_train, y_test,1, C_range_num = 100, \n",
    "                     nfold = 10, if_save = 0, if_show = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_tuning_all(pat, C_range_num, if_scaler = 1, if_remove_icd = 1, if_remove_sleep=1, if_save = 1, if_show = 0):\n",
    "    X_train, X_test, y_train, y_test = modules.get_ml_data(pat, if_scaler = if_scaler, if_remove_icd = if_remove_icd, if_remove_sleep = if_remove_sleep)\n",
    "    for classifier_int in tqdm.trange(1,hp.num_classifier + 1):\n",
    "        parameter_tuning(pat, X_train, X_test, y_train, y_test, C_range_num = C_range_num, classifier = classifier_int, if_save = if_save, if_show = if_show)\n",
    "    if if_save:\n",
    "        JJ.save_object(pat, hp.prepath_pat + pat.id +'_trained.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  1.0min finished\n",
      "\r",
      " 14%|█▍        | 1/7 [01:00<06:02, 60.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7469796964307782\n",
      "Best parameters: {'C': 0.0617229511459404, 'penalty': 'l2'}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   48.8s finished\n",
      " 57%|█████▋    | 4/7 [01:49<01:22, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7736183898145917\n",
      "Best parameters: {'C': 2.6647522377489268, 'gamma': 0.03571428571428571, 'kernel': 'rbf'}\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    4.5s finished\n",
      "\r",
      " 71%|███████▏  | 5/7 [01:54<00:45, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.70292164654577\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 60}\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  5.9min finished\n",
      " 86%|████████▌ | 6/7 [07:50<01:18, 78.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7759007885284585\n",
      "Best parameters: {'max_features': 'auto', 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20}\n",
      "Fitting 10 folds for each of 135 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed: 30.5min finished\n",
      "100%|██████████| 7/7 [38:24<00:00, 329.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.7666119182192485\n",
      "Best parameters: {'learning_rate': 0.005, 'min_samples_leaf': 30, 'max_depth': 3, 'subsample': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_tuning_all(p229, C_range_num = 100, if_scaler = hp.if_scaler, \n",
    "                     if_remove_icd = hp.if_remove_icd, if_remove_sleep = 1, if_save = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603351955307262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hp/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "JJ.ensemble_model(X_train, y_train, X_test, y_test, p231, if_save = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers removed: 19\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:   11.9s finished\n",
      "\r",
      " 14%|█▍        | 1/7 [00:11<01:11, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6607585081923943\n",
      "Best parameters: {'C': 0.19517445578083695, 'penalty': 'l1'}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   27.6s finished\n",
      "\r",
      " 29%|██▊       | 2/7 [00:39<01:38, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6867889496195189\n",
      "Best parameters: {'C': 4.90241546749882, 'kernel': 'rbf', 'gamma': 0.03571428571428571}\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    3.6s finished\n",
      "\r",
      " 71%|███████▏  | 5/7 [00:43<00:17,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6311262313615518\n",
      "Best parameters: {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 8}\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  5.1min finished\n",
      " 86%|████████▌ | 6/7 [05:50<00:58, 58.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6664817143862415\n",
      "Best parameters: {'max_features': 'auto', 'min_samples_split': 30, 'criterion': 'entropy', 'max_depth': 16}\n",
      "Fitting 10 folds for each of 135 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1350 out of 1350 | elapsed: 61.2min finished\n",
      "100%|██████████| 7/7 [1:07:02<00:00, 574.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for validations set: 0.6507336969013348\n",
      "Best parameters: {'learning_rate': 0.005, 'min_samples_leaf': 20, 'subsample': 0.2, 'max_depth': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_tuning_all(p222_1, C_range_num = 100, if_scaler = hp.if_scaler, if_remove_icd = hp.if_remove_icd, if_save = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
